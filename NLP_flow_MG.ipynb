{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d4d7429-dbdf-4be3-a62a-110d5035b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "135d00ba-395a-4095-b718-81411b3411c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.read_csv(\"original_data/books_data_with_index.csv\")\n",
    "books_df_subset = books_df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "858f881a-1532-4416-90f1-c5ace67ab37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/rv9lbyxx6l110tffps2wcg2r0000gn/T/ipykernel_30853/2422547884.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  books_df_subset[\"description_language\"] = books_df_subset[\"description\"].map(identify_language, na_action='ignore')\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"english_BOW\"] = \"\"\n"
     ]
    }
   ],
   "source": [
    "from NLP_preprocessing import create_BOW_feature_for_english_descriptions, add_BOW_PCA_to_df, identify_language\n",
    "\n",
    "books_df_subset[\"description_language\"] = books_df_subset[\"description\"].map(identify_language, na_action='ignore')\n",
    "create_BOW_feature_for_english_descriptions(books_df_subset, \"description\", \"english_BOW\")\n",
    "# add_BOW_PCA_to_df(books_df_subset, \"english_BOW\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96ff9417-0249-4215-8636-8d99214d4f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>categories</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>index</th>\n",
       "      <th>description_language</th>\n",
       "      <th>english_BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julie Strain']</td>\n",
       "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
       "      <td>A&amp;C Black</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>illustrator lane smith energetic cartoon surre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>planning worship fifteen practices congregatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005-02</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>sever car accident one day reunite miles away ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Edward Long']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-03-01</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                     Its Only Art If Its Well Hung!   \n",
       "1                           Dr. Seuss: American Icon   \n",
       "2              Wonderful Worship in Smaller Churches   \n",
       "3                      Whispers of the Wicked Saints   \n",
       "4  Nation Dance: Religion, Identity and Cultural ...   \n",
       "\n",
       "                                         description              authors  \\\n",
       "0                                                NaN     ['Julie Strain']   \n",
       "1  Philip Nel takes a fascinating look into the k...       ['Philip Nel']   \n",
       "2  This resource includes twelve principles in un...     ['David R. Ray']   \n",
       "3  Julia Thomas finds her life spinning out of co...  ['Veronica Haddon']   \n",
       "4                                                NaN      ['Edward Long']   \n",
       "\n",
       "                                               image  \\\n",
       "0  http://books.google.com/books/content?id=DykPA...   \n",
       "1  http://books.google.com/books/content?id=IjvHQ...   \n",
       "2  http://books.google.com/books/content?id=2tsDA...   \n",
       "3  http://books.google.com/books/content?id=aRSIg...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         previewLink  publisher publishedDate  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...        NaN          1996   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black    2005-01-01   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...        NaN          2000   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  iUniverse       2005-02   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...        NaN    2003-03-01   \n",
       "\n",
       "                                            infoLink  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
       "\n",
       "                      categories  ratingsCount  index description_language  \\\n",
       "0    ['Comics & Graphic Novels']           NaN      0                  NaN   \n",
       "1  ['Biography & Autobiography']           NaN      1              English   \n",
       "2                   ['Religion']           NaN      2              English   \n",
       "3                    ['Fiction']           NaN      3              English   \n",
       "4                            NaN           NaN      4                  NaN   \n",
       "\n",
       "                                         english_BOW  \n",
       "0                                                     \n",
       "1  illustrator lane smith energetic cartoon surre...  \n",
       "2  planning worship fifteen practices congregatio...  \n",
       "3  sever car accident one day reunite miles away ...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd5e62-f866-4fd0-af86-e4ca01b0e59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a7a60e7-4594-40e8-b8fa-dc27d37ab1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7760e05-b756-401c-8637-f4624173e44e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'add_TFIDF_PCA_to_df' from 'NLP_preprocessing' (/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNLP_preprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m identify_language, create_BOW_feature_for_english_descriptions, add_TFIDF_PCA_to_df\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'add_TFIDF_PCA_to_df' from 'NLP_preprocessing' (/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py)"
     ]
    }
   ],
   "source": [
    "from NLP_preprocessing import identify_language, create_BOW_feature_for_english_descriptions, add_TFIDF_PCA_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755a416-83a4-4258-b609-af5fe191a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out code from filipa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0c13ae2-ab1e-46b4-97a6-68b5cab5ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe that we want to process\n",
    "books_df = pd.read_csv(\"original_data/books_data_with_index.csv\")\n",
    "books_df_subset = books_df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0c8d155-c4a5-42ff-8a89-52888574ff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/rv9lbyxx6l110tffps2wcg2r0000gn/T/ipykernel_30853/2244310647.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  books_df_subset[\"description_language\"] = books_df_subset[\"description\"].map(identify_language, na_action='ignore')\n"
     ]
    }
   ],
   "source": [
    "# Identify the language of the book description and create a new feature in the given dataframe \n",
    "# called \"description_language\" that captures this label:\n",
    "\n",
    "books_df_subset[\"description_language\"] = books_df_subset[\"description\"].map(identify_language, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d435223c-76d6-455d-8023-9a4a23c4b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"english_BOW\"] = \"\"\n"
     ]
    }
   ],
   "source": [
    "# Create a bag of words for each row in the dataframe that has an english book description and save this in a \n",
    "# new column called \"english_BOW\". This bag of words feature transforms the book description into tokens that can be used\n",
    "# dimensionality reduction via PCA:\n",
    "create_BOW_feature_for_english_descriptions(books_df_subset, \"description\", \"english_BOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49ae0fb9-2b18-4a2a-88cf-a038cab5bf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n",
      "/Users/meganguidry/Documents/data_science_codeop/Group-project/NLP_preprocessing.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(location, f\"PC{i+1}\", PCA_components[:,i].tolist())\n"
     ]
    }
   ],
   "source": [
    "# A common practice is to choose a number of dimensions that add up to a sufficiently large portion of the \n",
    "# variance. Usually, a convention will be to retain 95% of the variance. Thus, we will input 0.95 for the thrid \n",
    "# argument in our PCA function below:\n",
    "\n",
    "pca_model = add_BOW_PCA_to_df(books_df_subset, \"english_BOW\", 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ea72563-0c68-43b0-bf11-2c400ada2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>categories</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>...</th>\n",
       "      <th>PC145</th>\n",
       "      <th>PC146</th>\n",
       "      <th>PC147</th>\n",
       "      <th>PC148</th>\n",
       "      <th>PC149</th>\n",
       "      <th>PC150</th>\n",
       "      <th>PC151</th>\n",
       "      <th>PC152</th>\n",
       "      <th>PC153</th>\n",
       "      <th>PC154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julie Strain']</td>\n",
       "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>-0.492777</td>\n",
       "      <td>-0.541506</td>\n",
       "      <td>-0.122563</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>-0.192165</td>\n",
       "      <td>0.180679</td>\n",
       "      <td>-0.477868</td>\n",
       "      <td>-0.194873</td>\n",
       "      <td>-0.253722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
       "      <td>A&amp;C Black</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206515</td>\n",
       "      <td>-0.312804</td>\n",
       "      <td>0.126912</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>0.018420</td>\n",
       "      <td>0.110120</td>\n",
       "      <td>0.103958</td>\n",
       "      <td>0.177774</td>\n",
       "      <td>0.041321</td>\n",
       "      <td>0.072313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  \\\n",
       "0  Its Only Art If Its Well Hung!   \n",
       "1        Dr. Seuss: American Icon   \n",
       "\n",
       "                                         description           authors  \\\n",
       "0                                                NaN  ['Julie Strain']   \n",
       "1  Philip Nel takes a fascinating look into the k...    ['Philip Nel']   \n",
       "\n",
       "                                               image  \\\n",
       "0  http://books.google.com/books/content?id=DykPA...   \n",
       "1  http://books.google.com/books/content?id=IjvHQ...   \n",
       "\n",
       "                                         previewLink  publisher publishedDate  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...        NaN          1996   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black    2005-01-01   \n",
       "\n",
       "                                            infoLink  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
       "\n",
       "                      categories  ratingsCount  ...     PC145     PC146  \\\n",
       "0    ['Comics & Graphic Novels']           NaN  ...  0.426339 -0.492777   \n",
       "1  ['Biography & Autobiography']           NaN  ... -0.206515 -0.312804   \n",
       "\n",
       "      PC147     PC148     PC149     PC150     PC151     PC152     PC153  \\\n",
       "0 -0.541506 -0.122563  0.019491 -0.192165  0.180679 -0.477868 -0.194873   \n",
       "1  0.126912 -0.006719  0.018420  0.110120  0.103958  0.177774  0.041321   \n",
       "\n",
       "      PC154  \n",
       "0 -0.253722  \n",
       "1  0.072313  \n",
       "\n",
       "[2 rows x 167 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df_subset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03ac4c66-d601-4bd4-819c-44b389bb63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504455951825566\n"
     ]
    }
   ],
   "source": [
    "print(pca_model.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce502e4-4f5b-44bb-b554-8ad503deb540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
