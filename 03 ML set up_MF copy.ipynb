{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up folders\n",
    "from EDA_functions import folders_set_up\n",
    "import os\n",
    "\n",
    "# Work with datarames\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charts\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# X, Y preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree\n",
    "\n",
    "# Neural Network\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Evaluate models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#from scipy.sparse import spmatrixc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM\n",
    "# import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folders\n",
    "Run the code below if you have the following structure:\n",
    "- Group-project: GitHub folder\n",
    "- 01 Input\n",
    "- 02 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_folder, input_folder, output_folder = folders_set_up.generate_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and merge data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Title', 'description', 'authors', 'image', 'previewLink',\n",
       "       'publisher', 'infoLink', 'categories', 'reviews number',\n",
       "       'average rating', 'median rating', 'min review date', 'max review date',\n",
       "       'weighted rating', 'date', 'year', 'description_language', 'Embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Title-level dataset with embeddings\n",
    "title_embeddings_df = pd.read_pickle(\n",
    "    os.path.join(output_folder, 'English_fiction_pre_PCA_3_with_av_pool_embeddings')\n",
    ")\n",
    "\n",
    "title_embeddings_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                     int64\n",
       "Title                    object\n",
       "description              object\n",
       "authors                  object\n",
       "image                    object\n",
       "previewLink              object\n",
       "publisher                object\n",
       "infoLink                 object\n",
       "categories               object\n",
       "reviews number            int64\n",
       "average rating          float64\n",
       "median rating           float64\n",
       "min review date          object\n",
       "max review date          object\n",
       "weighted rating         float64\n",
       "date                     object\n",
       "year                    float64\n",
       "description_language     object\n",
       "Embedding                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embeddings_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_columns = ['min review date', 'max review date', 'date']\n",
    "\n",
    "for date in dates_columns:\n",
    "    # get date from strings with time\n",
    "    title_embeddings_df[date] = title_embeddings_df[date].str.split().str[0]\n",
    "    # convert in datetime\n",
    "    title_embeddings_df[date] = pd.to_datetime(title_embeddings_df[date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min review date    0\n",
       "max review date    0\n",
       "date               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embeddings_df[dates_columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we work on a subset of data for now to make the ML run faster\n",
    "#title_embeddings_df = title_embeddings_df.sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image embeddings\n",
    "These need may need to be transformed in from arrays to columns if the model we use is not NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "Most of the cleaning is done in '02 Consolidate books dataset':\n",
    "- English description\n",
    "- category containing the word 'fiction'\n",
    "- non-missing date\n",
    "- non-missing author\n",
    "- non-missing publisher\n",
    "- non-missing cover image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X and y set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Title', 'description', 'authors', 'image', 'previewLink',\n",
       "       'publisher', 'infoLink', 'categories', 'reviews number',\n",
       "       'average rating', 'median rating', 'min review date', 'max review date',\n",
       "       'weighted rating', 'date', 'year', 'description_language', 'Embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embeddings_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y including all X features and all all teh possible target variables\n",
    "# NOTE: we will have to add the description PCA in X_features\n",
    "X_columns = ['year', 'Embedding', 'index', 'Title']\n",
    "\n",
    "X = title_embeddings_df[X_columns]\n",
    "y = title_embeddings_df[['average rating', 'weighted rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'Embedding', 'index', 'Title'], dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['average rating', 'weighted rating'], dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train test split\n",
    "\n",
    "# Need to create train test split for different combinations of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size= 0.2, \n",
    "    random_state= 42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store indices of train test split for the NLP of description\n",
    "train_indices = X_train[['Title', 'index']]\n",
    "test_indices = X_test[['Title', 'index']]\n",
    "\n",
    "train_indices.to_csv(\n",
    "    os.path.join(output_folder, 'train_indices.csv')\n",
    ")\n",
    "\n",
    "\n",
    "test_indices.to_csv(\n",
    "    os.path.join(output_folder, 'test_indices.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add NLP output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'description', 'authors', 'image', 'previewLink', 'publisher',\n",
       "       'infoLink', 'categories', 'index', 'reviews number',\n",
       "       ...\n",
       "       'tSVD2991', 'tSVD2992', 'tSVD2993', 'tSVD2994', 'tSVD2995', 'tSVD2996',\n",
       "       'tSVD2997', 'tSVD2998', 'tSVD2999', 'tSVD3000'],\n",
       "      dtype='object', length=3019)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description NLP test\n",
    "NLP_df_test = pd.read_csv(\n",
    "    os.path.join(output_folder, 'X_test_tSVD_3000.csv')\n",
    ")\n",
    "\n",
    "NLP_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'description', 'authors', 'image', 'previewLink', 'publisher',\n",
       "       'infoLink', 'categories', 'index', 'reviews number',\n",
       "       ...\n",
       "       'tSVD2991', 'tSVD2992', 'tSVD2993', 'tSVD2994', 'tSVD2995', 'tSVD2996',\n",
       "       'tSVD2997', 'tSVD2998', 'tSVD2999', 'tSVD3000'],\n",
       "      dtype='object', length=3019)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description NLP train\n",
    "NLP_df_train = pd.read_csv(\n",
    "    os.path.join(output_folder, 'X_train_tSVD_3000.csv')\n",
    ")\n",
    "NLP_df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['index'] + [col for col in NLP_df_test.columns if col.startswith('tSVD')]\n",
    "\n",
    "NLP_df_train = NLP_df_train[columns_to_keep]\n",
    "NLP_df_test = NLP_df_test[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train test datasets including description and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'Embedding', 'index', 'Title', 'tSVD1', 'tSVD2', 'tSVD3',\n",
       "       'tSVD4', 'tSVD5', 'tSVD6',\n",
       "       ...\n",
       "       'tSVD2991', 'tSVD2992', 'tSVD2993', 'tSVD2994', 'tSVD2995', 'tSVD2996',\n",
       "       'tSVD2997', 'tSVD2998', 'tSVD2999', 'tSVD3000'],\n",
       "      dtype='object', length=3004)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge X train with NLP train split\n",
    "X_train_full = pd.merge(\n",
    "    X_train,\n",
    "    NLP_df_train,\n",
    "    on = 'index',\n",
    "    how = 'inner'\n",
    ")\n",
    "\n",
    "X_train_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'Embedding', 'index', 'Title', 'tSVD1', 'tSVD2', 'tSVD3',\n",
       "       'tSVD4', 'tSVD5', 'tSVD6',\n",
       "       ...\n",
       "       'tSVD2991', 'tSVD2992', 'tSVD2993', 'tSVD2994', 'tSVD2995', 'tSVD2996',\n",
       "       'tSVD2997', 'tSVD2998', 'tSVD2999', 'tSVD3000'],\n",
       "      dtype='object', length=3004)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge X train with NLP test split\n",
    "X_test_full = pd.merge(\n",
    "    X_test,\n",
    "    NLP_df_test,\n",
    "    on = 'index',\n",
    "    how = 'inner'\n",
    ")\n",
    "\n",
    "X_test_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Title and idex\n",
    "X_train_full = X_train_full.drop(['Title', 'index'], axis = 1)\n",
    "X_test_full = X_test_full.drop(['Title', 'index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and y cuts\n",
    "We are going to run two models for two target variables\n",
    "- Target variable: Average rating\n",
    "  - baseline (i.e. excluding image embeddings)\n",
    "  - including image embeddings\n",
    "- Target variable: weighted rating\n",
    "  - baseline (i.e. excluding image embeddings)\n",
    "  - including image embeddings\n",
    "\n",
    "We therefore need to create the following datsets\n",
    "- X train and X test with embeddings\n",
    "- X train and X text without embeddings\n",
    "- y train and y test using average rating\n",
    "- y train and y test using weighted rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model data\n",
    "X_baseline_train = X_train_full.drop('Embedding', axis = 1)\n",
    "X_baseline_test = X_test_full.drop('Embedding', axis = 1)\n",
    "\n",
    "# Y train with average rating\n",
    "y_avg_r_train = y_train['average rating']\n",
    "y_avg_r_test = y_test['average rating']\n",
    "\n",
    "# Y train with weighted rating\n",
    "y_wr_train = y_train['weighted rating']\n",
    "y_wr_test = y_test['weighted rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21419, 3001)\n",
      "(5355, 3001)\n"
     ]
    }
   ],
   "source": [
    "print(X_baseline_train.shape)\n",
    "print(X_baseline_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images_train = X_train['Embedding'].apply(pd.Series)\n",
    "X_images_test = X_test['Embedding'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18094</th>\n",
       "      <td>1.836475</td>\n",
       "      <td>-0.497749</td>\n",
       "      <td>-0.934198</td>\n",
       "      <td>-0.700033</td>\n",
       "      <td>-0.183123</td>\n",
       "      <td>-0.457912</td>\n",
       "      <td>-0.280106</td>\n",
       "      <td>-0.600373</td>\n",
       "      <td>1.840422</td>\n",
       "      <td>0.901016</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104014</td>\n",
       "      <td>1.616048</td>\n",
       "      <td>-2.514497</td>\n",
       "      <td>-4.208746</td>\n",
       "      <td>-0.098694</td>\n",
       "      <td>1.582575</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>1.575465</td>\n",
       "      <td>1.193311</td>\n",
       "      <td>-2.050111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>0.205656</td>\n",
       "      <td>0.791968</td>\n",
       "      <td>0.405043</td>\n",
       "      <td>-1.060780</td>\n",
       "      <td>0.118351</td>\n",
       "      <td>-1.244569</td>\n",
       "      <td>-1.545293</td>\n",
       "      <td>-0.671695</td>\n",
       "      <td>-0.686115</td>\n",
       "      <td>1.250351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078643</td>\n",
       "      <td>-2.672630</td>\n",
       "      <td>-3.056665</td>\n",
       "      <td>-1.075442</td>\n",
       "      <td>0.566942</td>\n",
       "      <td>1.214506</td>\n",
       "      <td>-0.765949</td>\n",
       "      <td>-0.835964</td>\n",
       "      <td>1.480691</td>\n",
       "      <td>-1.776814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21240</th>\n",
       "      <td>0.930151</td>\n",
       "      <td>0.571199</td>\n",
       "      <td>-2.055533</td>\n",
       "      <td>-1.008831</td>\n",
       "      <td>1.015776</td>\n",
       "      <td>0.384367</td>\n",
       "      <td>0.314018</td>\n",
       "      <td>0.082096</td>\n",
       "      <td>0.733199</td>\n",
       "      <td>0.296620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>-1.222809</td>\n",
       "      <td>-2.141979</td>\n",
       "      <td>-0.946069</td>\n",
       "      <td>-0.660697</td>\n",
       "      <td>-0.262918</td>\n",
       "      <td>-0.767982</td>\n",
       "      <td>1.251583</td>\n",
       "      <td>0.774267</td>\n",
       "      <td>-1.925034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>1.278287</td>\n",
       "      <td>1.026899</td>\n",
       "      <td>-1.305843</td>\n",
       "      <td>-0.473169</td>\n",
       "      <td>-0.343535</td>\n",
       "      <td>-0.259604</td>\n",
       "      <td>-0.285320</td>\n",
       "      <td>0.125091</td>\n",
       "      <td>0.764422</td>\n",
       "      <td>-1.185505</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278345</td>\n",
       "      <td>-0.392527</td>\n",
       "      <td>-0.233589</td>\n",
       "      <td>-1.632104</td>\n",
       "      <td>1.350724</td>\n",
       "      <td>-0.440483</td>\n",
       "      <td>0.112697</td>\n",
       "      <td>1.445008</td>\n",
       "      <td>1.684287</td>\n",
       "      <td>-2.700428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8882</th>\n",
       "      <td>2.203120</td>\n",
       "      <td>1.502297</td>\n",
       "      <td>-1.191875</td>\n",
       "      <td>-0.953792</td>\n",
       "      <td>-0.141903</td>\n",
       "      <td>0.928510</td>\n",
       "      <td>-0.490275</td>\n",
       "      <td>-0.237004</td>\n",
       "      <td>2.103021</td>\n",
       "      <td>-0.426597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912975</td>\n",
       "      <td>-0.281342</td>\n",
       "      <td>-2.052552</td>\n",
       "      <td>-1.181523</td>\n",
       "      <td>-0.322459</td>\n",
       "      <td>-1.299769</td>\n",
       "      <td>-1.665321</td>\n",
       "      <td>0.238138</td>\n",
       "      <td>1.767898</td>\n",
       "      <td>-1.486802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>1.050755</td>\n",
       "      <td>-1.591885</td>\n",
       "      <td>-2.350058</td>\n",
       "      <td>-0.953110</td>\n",
       "      <td>0.647061</td>\n",
       "      <td>-0.311001</td>\n",
       "      <td>-0.748348</td>\n",
       "      <td>0.373362</td>\n",
       "      <td>-0.387882</td>\n",
       "      <td>1.047025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200192</td>\n",
       "      <td>0.252263</td>\n",
       "      <td>-1.823197</td>\n",
       "      <td>-2.419869</td>\n",
       "      <td>-0.559653</td>\n",
       "      <td>1.133909</td>\n",
       "      <td>-0.333365</td>\n",
       "      <td>0.801189</td>\n",
       "      <td>-0.999478</td>\n",
       "      <td>-3.890836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14807</th>\n",
       "      <td>1.474814</td>\n",
       "      <td>-0.414877</td>\n",
       "      <td>-1.244418</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>0.142872</td>\n",
       "      <td>-0.770006</td>\n",
       "      <td>-0.378338</td>\n",
       "      <td>1.122426</td>\n",
       "      <td>0.560395</td>\n",
       "      <td>-0.992234</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176295</td>\n",
       "      <td>1.091057</td>\n",
       "      <td>-1.040878</td>\n",
       "      <td>1.289441</td>\n",
       "      <td>-0.142611</td>\n",
       "      <td>-0.594793</td>\n",
       "      <td>-0.160397</td>\n",
       "      <td>-0.775595</td>\n",
       "      <td>2.140052</td>\n",
       "      <td>-1.167046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>0.104982</td>\n",
       "      <td>-1.683177</td>\n",
       "      <td>-2.318883</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>-0.592815</td>\n",
       "      <td>0.895470</td>\n",
       "      <td>-2.075084</td>\n",
       "      <td>-0.088912</td>\n",
       "      <td>1.376224</td>\n",
       "      <td>-0.365895</td>\n",
       "      <td>...</td>\n",
       "      <td>1.459096</td>\n",
       "      <td>-0.379034</td>\n",
       "      <td>0.950986</td>\n",
       "      <td>-1.437364</td>\n",
       "      <td>-0.515036</td>\n",
       "      <td>-0.798989</td>\n",
       "      <td>0.203845</td>\n",
       "      <td>2.042672</td>\n",
       "      <td>2.153734</td>\n",
       "      <td>-0.287360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21911</th>\n",
       "      <td>1.764822</td>\n",
       "      <td>0.718472</td>\n",
       "      <td>-0.340942</td>\n",
       "      <td>-0.222711</td>\n",
       "      <td>-1.331447</td>\n",
       "      <td>-0.147405</td>\n",
       "      <td>-2.655680</td>\n",
       "      <td>-0.189822</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>-1.348953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761795</td>\n",
       "      <td>-1.367549</td>\n",
       "      <td>-1.470985</td>\n",
       "      <td>-1.775654</td>\n",
       "      <td>0.239348</td>\n",
       "      <td>-0.552941</td>\n",
       "      <td>-1.093193</td>\n",
       "      <td>-0.551422</td>\n",
       "      <td>0.974623</td>\n",
       "      <td>-1.854537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>0.498746</td>\n",
       "      <td>1.551936</td>\n",
       "      <td>-1.656965</td>\n",
       "      <td>-1.678264</td>\n",
       "      <td>0.461710</td>\n",
       "      <td>-0.783551</td>\n",
       "      <td>0.474597</td>\n",
       "      <td>-1.002431</td>\n",
       "      <td>1.283821</td>\n",
       "      <td>1.152644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755233</td>\n",
       "      <td>0.953165</td>\n",
       "      <td>-1.942051</td>\n",
       "      <td>-1.751575</td>\n",
       "      <td>0.387150</td>\n",
       "      <td>0.308334</td>\n",
       "      <td>1.150342</td>\n",
       "      <td>0.244955</td>\n",
       "      <td>1.253789</td>\n",
       "      <td>-1.837545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5355 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "18094  1.836475 -0.497749 -0.934198 -0.700033 -0.183123 -0.457912 -0.280106   \n",
       "9755   0.205656  0.791968  0.405043 -1.060780  0.118351 -1.244569 -1.545293   \n",
       "21240  0.930151  0.571199 -2.055533 -1.008831  1.015776  0.384367  0.314018   \n",
       "6725   1.278287  1.026899 -1.305843 -0.473169 -0.343535 -0.259604 -0.285320   \n",
       "8882   2.203120  1.502297 -1.191875 -0.953792 -0.141903  0.928510 -0.490275   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "5096   1.050755 -1.591885 -2.350058 -0.953110  0.647061 -0.311001 -0.748348   \n",
       "14807  1.474814 -0.414877 -1.244418  0.905722  0.142872 -0.770006 -0.378338   \n",
       "7376   0.104982 -1.683177 -2.318883  0.529517 -0.592815  0.895470 -2.075084   \n",
       "21911  1.764822  0.718472 -0.340942 -0.222711 -1.331447 -0.147405 -2.655680   \n",
       "5414   0.498746  1.551936 -1.656965 -1.678264  0.461710 -0.783551  0.474597   \n",
       "\n",
       "            7         8         9    ...       246       247       248  \\\n",
       "18094 -0.600373  1.840422  0.901016  ...  2.104014  1.616048 -2.514497   \n",
       "9755  -0.671695 -0.686115  1.250351  ...  0.078643 -2.672630 -3.056665   \n",
       "21240  0.082096  0.733199  0.296620  ...  0.742268 -1.222809 -2.141979   \n",
       "6725   0.125091  0.764422 -1.185505  ...  2.278345 -0.392527 -0.233589   \n",
       "8882  -0.237004  2.103021 -0.426597  ...  0.912975 -0.281342 -2.052552   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "5096   0.373362 -0.387882  1.047025  ... -0.200192  0.252263 -1.823197   \n",
       "14807  1.122426  0.560395 -0.992234  ...  1.176295  1.091057 -1.040878   \n",
       "7376  -0.088912  1.376224 -0.365895  ...  1.459096 -0.379034  0.950986   \n",
       "21911 -0.189822  0.872460 -1.348953  ... -0.761795 -1.367549 -1.470985   \n",
       "5414  -1.002431  1.283821  1.152644  ...  0.755233  0.953165 -1.942051   \n",
       "\n",
       "            249       250       251       252       253       254       255  \n",
       "18094 -4.208746 -0.098694  1.582575  0.489796  1.575465  1.193311 -2.050111  \n",
       "9755  -1.075442  0.566942  1.214506 -0.765949 -0.835964  1.480691 -1.776814  \n",
       "21240 -0.946069 -0.660697 -0.262918 -0.767982  1.251583  0.774267 -1.925034  \n",
       "6725  -1.632104  1.350724 -0.440483  0.112697  1.445008  1.684287 -2.700428  \n",
       "8882  -1.181523 -0.322459 -1.299769 -1.665321  0.238138  1.767898 -1.486802  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "5096  -2.419869 -0.559653  1.133909 -0.333365  0.801189 -0.999478 -3.890836  \n",
       "14807  1.289441 -0.142611 -0.594793 -0.160397 -0.775595  2.140052 -1.167046  \n",
       "7376  -1.437364 -0.515036 -0.798989  0.203845  2.042672  2.153734 -0.287360  \n",
       "21911 -1.775654  0.239348 -0.552941 -1.093193 -0.551422  0.974623 -1.854537  \n",
       "5414  -1.751575  0.387150  0.308334  1.150342  0.244955  1.253789 -1.837545  \n",
       "\n",
       "[5355 rows x 256 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_images_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description dimension reduction NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Questions/notes:\n",
    "Inputs to choose:\n",
    "- number of layers:\n",
    "    - Description NN\n",
    "        - input\n",
    "        - noise\n",
    "        - hidden layer\n",
    "        - noise\n",
    "        - hidden layer\n",
    "        - final layer\n",
    "    - Description and image embeddings NN\n",
    "        - input\n",
    "        - noise\n",
    "        - hidden layer\n",
    "        - noise\n",
    "        - final layer\n",
    "    Too many?   \n",
    "- add dense layers to avoid overfitting?\n",
    "- activation functions\n",
    "    - ReLu (Rectified linear activation function): piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. Simple but effective.\n",
    "- Use linear in the last layer to obtain a continuous variable\n",
    "- optimizer: \n",
    "    - Adam; works with momentums of first and second order. \n",
    "    - sdg: variant of Gradient Descent (Gradient Descent is the most basic but most used optimization algorithm. It’s used heavily in linear regression and classification algorithms. It's easy and works well but there is the risk that the model gets stuck in local minima)\n",
    "- loss function\n",
    "    - MSE?\n",
    "- number of epochs\n",
    "- which metric to use to evaluate the model?\n",
    "    - MSE\n",
    "    - MAE\n",
    "\n",
    "- Use gridsearch to optimise hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21419, 3001)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_baseline_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_baseline_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesrezgui/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,537,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,537,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,668,352</span> (6.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,668,352\u001b[0m (6.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,668,352</span> (6.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,668,352\u001b[0m (6.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get number of inputs - second element of shape (i.e. number of columns in X)\n",
    "input_shape = X_baseline_train.shape[1]\n",
    "\n",
    "# neurons number\n",
    "n_neurons = 512\n",
    "\n",
    "# define a model\n",
    "baseline_model = keras.Sequential()\n",
    "\n",
    "# Add input layer\n",
    "baseline_model.add(layers.Dense(\n",
    "            n_neurons, # number of neurons\n",
    "            input_dim = input_shape, # number of inputs \n",
    "            activation = 'relu' # activation faunction\n",
    "            ))\n",
    "\n",
    "# Hidden - Layers\n",
    "baseline_model.add(layers.Dense(\n",
    "                    256, \n",
    "                    activation = \"linear\"))\n",
    "\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=['mean_squared_error'], \n",
    "    metrics = ['mae', 'mean_squared_error']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m  9/429\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 743.7336 - mae: 18.9162 - mean_squared_error: 743.7335      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 54.7727 - mae: 2.4568 - mean_squared_error: 54.7728 - val_loss: 0.0479 - val_mae: 0.1420 - val_mean_squared_error: 0.0462\n",
      "Epoch 2/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0470 - mae: 0.1422 - mean_squared_error: 0.0470 - val_loss: 0.0514 - val_mae: 0.1460 - val_mean_squared_error: 0.0496\n",
      "Epoch 3/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0457 - mae: 0.1432 - mean_squared_error: 0.0457 - val_loss: 0.0511 - val_mae: 0.1530 - val_mean_squared_error: 0.0494\n",
      "Epoch 4/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0467 - mae: 0.1480 - mean_squared_error: 0.0467 - val_loss: 0.0725 - val_mae: 0.1818 - val_mean_squared_error: 0.0704\n",
      "Epoch 5/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0502 - mae: 0.1534 - mean_squared_error: 0.0502 - val_loss: 0.0560 - val_mae: 0.1571 - val_mean_squared_error: 0.0543\n",
      "Epoch 6/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0513 - mae: 0.1563 - mean_squared_error: 0.0513 - val_loss: 0.0534 - val_mae: 0.1607 - val_mean_squared_error: 0.0519\n",
      "Epoch 7/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0539 - mae: 0.1606 - mean_squared_error: 0.0539 - val_loss: 0.0851 - val_mae: 0.2012 - val_mean_squared_error: 0.0830\n",
      "Epoch 8/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0591 - mae: 0.1731 - mean_squared_error: 0.0591 - val_loss: 0.0701 - val_mae: 0.1789 - val_mean_squared_error: 0.0682\n",
      "Epoch 9/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0536 - mae: 0.1631 - mean_squared_error: 0.0536 - val_loss: 0.1038 - val_mae: 0.2511 - val_mean_squared_error: 0.1028\n",
      "Epoch 10/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0561 - mae: 0.1704 - mean_squared_error: 0.0561 - val_loss: 0.0696 - val_mae: 0.1880 - val_mean_squared_error: 0.0682\n",
      "Epoch 11/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0557 - mae: 0.1703 - mean_squared_error: 0.0557 - val_loss: 0.0833 - val_mae: 0.2361 - val_mean_squared_error: 0.0824\n",
      "Epoch 12/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0575 - mae: 0.1744 - mean_squared_error: 0.0575 - val_loss: 0.0566 - val_mae: 0.1735 - val_mean_squared_error: 0.0554\n",
      "Epoch 13/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0488 - mae: 0.1592 - mean_squared_error: 0.0488 - val_loss: 0.0597 - val_mae: 0.1657 - val_mean_squared_error: 0.0582\n",
      "Epoch 14/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0500 - mae: 0.1616 - mean_squared_error: 0.0500 - val_loss: 0.0875 - val_mae: 0.2199 - val_mean_squared_error: 0.0861\n",
      "Epoch 15/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0471 - mae: 0.1573 - mean_squared_error: 0.0471 - val_loss: 0.0505 - val_mae: 0.1547 - val_mean_squared_error: 0.0493\n",
      "Epoch 16/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0477 - mae: 0.1563 - mean_squared_error: 0.0477 - val_loss: 0.0587 - val_mae: 0.1678 - val_mean_squared_error: 0.0574\n",
      "Epoch 17/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0474 - mae: 0.1581 - mean_squared_error: 0.0474 - val_loss: 0.0585 - val_mae: 0.1853 - val_mean_squared_error: 0.0577\n",
      "Epoch 18/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0431 - mae: 0.1507 - mean_squared_error: 0.0431 - val_loss: 0.0531 - val_mae: 0.1635 - val_mean_squared_error: 0.0520\n",
      "Epoch 19/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0465 - mae: 0.1579 - mean_squared_error: 0.0465 - val_loss: 0.0633 - val_mae: 0.1916 - val_mean_squared_error: 0.0624\n",
      "Epoch 20/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0495 - mae: 0.1624 - mean_squared_error: 0.0495 - val_loss: 0.0551 - val_mae: 0.1691 - val_mean_squared_error: 0.0540\n",
      "Epoch 21/100\n",
      "\u001b[1m254/429\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0430 - mae: 0.1501 - mean_squared_error: 0.0430"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m epochs_hist \u001b[38;5;241m=\u001b[39m \u001b[43mbaseline_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_baseline_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# input\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_wr_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# output\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# number of iterations\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# number of observations taken to train the data\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_baseline_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_wr_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#validation_split=0.2,    \u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs_hist = baseline_model.fit(\n",
    "    X_baseline_train, # input\n",
    "    y_wr_train, # output\n",
    "    epochs=100, # number of iterations\n",
    "    batch_size=50, # number of observations taken to train the data\n",
    "    verbose=1,\n",
    "    validation_data = (X_baseline_test, y_wr_test),\n",
    "    shuffle = True\n",
    "    #validation_split=0.2,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate description embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict baseline X train and X test \n",
    "\n",
    "X_intermediate_train = baseline_model.predict(X_baseline_train)\n",
    "X_intermediate_test = baseline_model.predict(X_baseline_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3383527, 4.340892 , 4.316981 , ..., 4.332548 , 4.335368 ,\n",
       "        4.3374715],\n",
       "       [4.159111 , 4.1591816, 4.1422048, ..., 4.1680446, 4.16055  ,\n",
       "        4.154699 ],\n",
       "       [4.2181926, 4.219371 , 4.2000895, ..., 4.2215304, 4.2182364,\n",
       "        4.2152433],\n",
       "       ...,\n",
       "       [4.177903 , 4.179436 , 4.163506 , ..., 4.184822 , 4.1816344,\n",
       "        4.1752453],\n",
       "       [4.304187 , 4.3046947, 4.282489 , ..., 4.2989907, 4.298301 ,\n",
       "        4.3012238],\n",
       "       [4.13071  , 4.133052 , 4.1169972, ..., 4.14305  , 4.1364284,\n",
       "        4.1283064]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_intermediate_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(X_intermediate_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store these into a dataframe\n",
    "X_intermediate_train_df = pd.DataFrame(X_intermediate_train, index=X_baseline_train.index)\n",
    "X_intermediate_test_df = pd.DataFrame(X_intermediate_test, index=X_baseline_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21419, 256)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_intermediate_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression & co."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "\n",
    "# Random forest\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# SVR\n",
    "svr_model = SVR(kernel='rbf')  # 'rbf' for radial basis function kernel\n",
    "\n",
    "# Lightgbm\n",
    "\n",
    "\n",
    "# Define pipeline steps\n",
    "rf_pipeline = Pipeline([\n",
    "    ('rf', rf)  # Random Forest classifier\n",
    "])\n",
    "\n",
    "svr_pipeline = Pipeline([\n",
    "    ('svr', svr_model)  # Neural Network classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Regression</th>\n",
       "      <td>(SVR())</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model prediction   MAE   MSE\n",
       "Support Vector Regression  (SVR())       None  None  None"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics = pd.DataFrame({\n",
    "    #'Random Forest': {'model': rf_pipeline, 'prediction' : None, 'MAE' : None, 'MSE' : None},\n",
    "    'Support Vector Regression': {'model': svr_pipeline, 'X_train': X_baseline_train, 'X_test' : X_baseline_test, 'prediction': None, 'MAE' : None, 'MSE' : None}\n",
    "}).transpose()\n",
    "\n",
    "evaluation_metrics = evaluation_metrics.rename(\n",
    "    columns  = {'index' : 'model name'}\n",
    ")\n",
    "\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression & co."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict\n",
    "\n",
    "for i, row in evaluation_metrics.iterrows():\n",
    "\n",
    "    print(i)\n",
    "    # Call model\n",
    "    model = row['model']\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(row['X_train'], y_wr_train)\n",
    "\n",
    "    # Calculate predictions\n",
    "    y_wr_pred = model.predict(row['X_test'])\n",
    "\n",
    "    # save predictions\n",
    "    row['prediction'] = y_wr_pred\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_wr_test, y_wr_pred)\n",
    "    mae = mean_absolute_error(y_wr_test, y_wr_pred)\n",
    "\n",
    "    # Save metrics\n",
    "    row['MAE'] = mae\n",
    "    row['MSE'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Regression</th>\n",
       "      <td>(SVR())</td>\n",
       "      <td>[4.265525836702388, 4.260213607671864, 4.26396...</td>\n",
       "      <td>0.131576</td>\n",
       "      <td>0.045234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  \\\n",
       "Support Vector Regression  (SVR())   \n",
       "\n",
       "                                                                  prediction  \\\n",
       "Support Vector Regression  [4.265525836702388, 4.260213607671864, 4.26396...   \n",
       "\n",
       "                                MAE       MSE  \n",
       "Support Vector Regression  0.131576  0.045234  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack description + publish year and images embeddings\n",
    "\n",
    "X_final_train = pd.merge(\n",
    "    X_intermediate_train_df, \n",
    "    X_images_train, left_index = True, right_index = True)\n",
    "\n",
    "X_final_test = pd.merge(\n",
    "    X_intermediate_test_df, \n",
    "    X_images_test, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>...</th>\n",
       "      <th>246_y</th>\n",
       "      <th>247_y</th>\n",
       "      <th>248_y</th>\n",
       "      <th>249_y</th>\n",
       "      <th>250_y</th>\n",
       "      <th>251_y</th>\n",
       "      <th>252_y</th>\n",
       "      <th>253_y</th>\n",
       "      <th>254_y</th>\n",
       "      <th>255_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.338353</td>\n",
       "      <td>4.340892</td>\n",
       "      <td>4.316981</td>\n",
       "      <td>4.320763</td>\n",
       "      <td>4.318037</td>\n",
       "      <td>4.325047</td>\n",
       "      <td>4.327944</td>\n",
       "      <td>4.326110</td>\n",
       "      <td>4.324330</td>\n",
       "      <td>4.332526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771862</td>\n",
       "      <td>-0.937564</td>\n",
       "      <td>0.160219</td>\n",
       "      <td>-3.918411</td>\n",
       "      <td>1.290541</td>\n",
       "      <td>0.105171</td>\n",
       "      <td>-0.638527</td>\n",
       "      <td>1.798588</td>\n",
       "      <td>0.194572</td>\n",
       "      <td>-0.449297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.159111</td>\n",
       "      <td>4.159182</td>\n",
       "      <td>4.142205</td>\n",
       "      <td>4.157333</td>\n",
       "      <td>4.160525</td>\n",
       "      <td>4.164882</td>\n",
       "      <td>4.151037</td>\n",
       "      <td>4.165454</td>\n",
       "      <td>4.163754</td>\n",
       "      <td>4.156608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046784</td>\n",
       "      <td>-0.342466</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>-0.539784</td>\n",
       "      <td>-0.446947</td>\n",
       "      <td>-0.678967</td>\n",
       "      <td>-1.103884</td>\n",
       "      <td>0.034339</td>\n",
       "      <td>2.301175</td>\n",
       "      <td>-1.253411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.218193</td>\n",
       "      <td>4.219371</td>\n",
       "      <td>4.200089</td>\n",
       "      <td>4.210188</td>\n",
       "      <td>4.211071</td>\n",
       "      <td>4.216390</td>\n",
       "      <td>4.209805</td>\n",
       "      <td>4.217251</td>\n",
       "      <td>4.215663</td>\n",
       "      <td>4.214536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.927017</td>\n",
       "      <td>0.528925</td>\n",
       "      <td>-2.372087</td>\n",
       "      <td>-3.646941</td>\n",
       "      <td>-0.907056</td>\n",
       "      <td>0.847365</td>\n",
       "      <td>-0.013004</td>\n",
       "      <td>1.382128</td>\n",
       "      <td>0.247746</td>\n",
       "      <td>-0.094255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.261648</td>\n",
       "      <td>4.264165</td>\n",
       "      <td>4.242680</td>\n",
       "      <td>4.244533</td>\n",
       "      <td>4.241865</td>\n",
       "      <td>4.248337</td>\n",
       "      <td>4.253148</td>\n",
       "      <td>4.248696</td>\n",
       "      <td>4.247474</td>\n",
       "      <td>4.255553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770220</td>\n",
       "      <td>-0.087095</td>\n",
       "      <td>-0.887185</td>\n",
       "      <td>-0.658820</td>\n",
       "      <td>0.497890</td>\n",
       "      <td>1.214699</td>\n",
       "      <td>0.595776</td>\n",
       "      <td>-1.266087</td>\n",
       "      <td>1.119841</td>\n",
       "      <td>-1.130244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.285786</td>\n",
       "      <td>4.286593</td>\n",
       "      <td>4.263547</td>\n",
       "      <td>4.268418</td>\n",
       "      <td>4.266219</td>\n",
       "      <td>4.274320</td>\n",
       "      <td>4.274791</td>\n",
       "      <td>4.273934</td>\n",
       "      <td>4.272595</td>\n",
       "      <td>4.278882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453792</td>\n",
       "      <td>-2.110143</td>\n",
       "      <td>-1.831928</td>\n",
       "      <td>-1.629754</td>\n",
       "      <td>0.260345</td>\n",
       "      <td>-0.725871</td>\n",
       "      <td>0.169176</td>\n",
       "      <td>0.694780</td>\n",
       "      <td>0.520172</td>\n",
       "      <td>-1.661646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>4.170748</td>\n",
       "      <td>4.171540</td>\n",
       "      <td>4.154922</td>\n",
       "      <td>4.168193</td>\n",
       "      <td>4.171078</td>\n",
       "      <td>4.173747</td>\n",
       "      <td>4.163568</td>\n",
       "      <td>4.175552</td>\n",
       "      <td>4.172836</td>\n",
       "      <td>4.168675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703468</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.634626</td>\n",
       "      <td>-3.269752</td>\n",
       "      <td>0.528702</td>\n",
       "      <td>-0.219437</td>\n",
       "      <td>-0.826503</td>\n",
       "      <td>0.487110</td>\n",
       "      <td>1.537434</td>\n",
       "      <td>-2.034658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>4.171724</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>4.153270</td>\n",
       "      <td>4.162176</td>\n",
       "      <td>4.162246</td>\n",
       "      <td>4.168887</td>\n",
       "      <td>4.162664</td>\n",
       "      <td>4.168126</td>\n",
       "      <td>4.167743</td>\n",
       "      <td>4.166468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109090</td>\n",
       "      <td>-1.139498</td>\n",
       "      <td>-2.483485</td>\n",
       "      <td>-1.942593</td>\n",
       "      <td>1.304554</td>\n",
       "      <td>1.074131</td>\n",
       "      <td>0.864786</td>\n",
       "      <td>-0.690940</td>\n",
       "      <td>2.138776</td>\n",
       "      <td>-3.094906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>4.240297</td>\n",
       "      <td>4.241666</td>\n",
       "      <td>4.221805</td>\n",
       "      <td>4.229430</td>\n",
       "      <td>4.229227</td>\n",
       "      <td>4.235040</td>\n",
       "      <td>4.231710</td>\n",
       "      <td>4.235931</td>\n",
       "      <td>4.234513</td>\n",
       "      <td>4.235995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800764</td>\n",
       "      <td>1.386447</td>\n",
       "      <td>-0.541234</td>\n",
       "      <td>-3.030559</td>\n",
       "      <td>0.918972</td>\n",
       "      <td>-0.509071</td>\n",
       "      <td>-0.463985</td>\n",
       "      <td>1.426476</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>-0.430397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>4.177903</td>\n",
       "      <td>4.179436</td>\n",
       "      <td>4.163506</td>\n",
       "      <td>4.174832</td>\n",
       "      <td>4.177389</td>\n",
       "      <td>4.179801</td>\n",
       "      <td>4.172066</td>\n",
       "      <td>4.182162</td>\n",
       "      <td>4.179721</td>\n",
       "      <td>4.176424</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000795</td>\n",
       "      <td>0.858295</td>\n",
       "      <td>-0.646890</td>\n",
       "      <td>-3.251756</td>\n",
       "      <td>1.294001</td>\n",
       "      <td>0.302334</td>\n",
       "      <td>1.666978</td>\n",
       "      <td>-0.167826</td>\n",
       "      <td>0.217958</td>\n",
       "      <td>-2.211897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21417</th>\n",
       "      <td>4.304187</td>\n",
       "      <td>4.304695</td>\n",
       "      <td>4.282489</td>\n",
       "      <td>4.286576</td>\n",
       "      <td>4.283604</td>\n",
       "      <td>4.292859</td>\n",
       "      <td>4.292573</td>\n",
       "      <td>4.291720</td>\n",
       "      <td>4.291728</td>\n",
       "      <td>4.296960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619482</td>\n",
       "      <td>1.248062</td>\n",
       "      <td>0.165214</td>\n",
       "      <td>-2.897301</td>\n",
       "      <td>-0.001716</td>\n",
       "      <td>0.158579</td>\n",
       "      <td>-0.979520</td>\n",
       "      <td>0.039815</td>\n",
       "      <td>1.450755</td>\n",
       "      <td>0.442973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17114 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0_x       1_x       2_x       3_x       4_x       5_x       6_x  \\\n",
       "0      4.338353  4.340892  4.316981  4.320763  4.318037  4.325047  4.327944   \n",
       "1      4.159111  4.159182  4.142205  4.157333  4.160525  4.164882  4.151037   \n",
       "2      4.218193  4.219371  4.200089  4.210188  4.211071  4.216390  4.209805   \n",
       "3      4.261648  4.264165  4.242680  4.244533  4.241865  4.248337  4.253148   \n",
       "4      4.285786  4.286593  4.263547  4.268418  4.266219  4.274320  4.274791   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21413  4.170748  4.171540  4.154922  4.168193  4.171078  4.173747  4.163568   \n",
       "21414  4.171724  4.172228  4.153270  4.162176  4.162246  4.168887  4.162664   \n",
       "21415  4.240297  4.241666  4.221805  4.229430  4.229227  4.235040  4.231710   \n",
       "21416  4.177903  4.179436  4.163506  4.174832  4.177389  4.179801  4.172066   \n",
       "21417  4.304187  4.304695  4.282489  4.286576  4.283604  4.292859  4.292573   \n",
       "\n",
       "            7_x       8_x       9_x  ...     246_y     247_y     248_y  \\\n",
       "0      4.326110  4.324330  4.332526  ...  0.771862 -0.937564  0.160219   \n",
       "1      4.165454  4.163754  4.156608  ... -0.046784 -0.342466  0.034356   \n",
       "2      4.217251  4.215663  4.214536  ... -0.927017  0.528925 -2.372087   \n",
       "3      4.248696  4.247474  4.255553  ...  0.770220 -0.087095 -0.887185   \n",
       "4      4.273934  4.272595  4.278882  ... -0.453792 -2.110143 -1.831928   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21413  4.175552  4.172836  4.168675  ...  0.703468  0.611814  0.634626   \n",
       "21414  4.168126  4.167743  4.166468  ...  0.109090 -1.139498 -2.483485   \n",
       "21415  4.235931  4.234513  4.235995  ...  0.800764  1.386447 -0.541234   \n",
       "21416  4.182162  4.179721  4.176424  ...  1.000795  0.858295 -0.646890   \n",
       "21417  4.291720  4.291728  4.296960  ...  0.619482  1.248062  0.165214   \n",
       "\n",
       "          249_y     250_y     251_y     252_y     253_y     254_y     255_y  \n",
       "0     -3.918411  1.290541  0.105171 -0.638527  1.798588  0.194572 -0.449297  \n",
       "1     -0.539784 -0.446947 -0.678967 -1.103884  0.034339  2.301175 -1.253411  \n",
       "2     -3.646941 -0.907056  0.847365 -0.013004  1.382128  0.247746 -0.094255  \n",
       "3     -0.658820  0.497890  1.214699  0.595776 -1.266087  1.119841 -1.130244  \n",
       "4     -1.629754  0.260345 -0.725871  0.169176  0.694780  0.520172 -1.661646  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21413 -3.269752  0.528702 -0.219437 -0.826503  0.487110  1.537434 -2.034658  \n",
       "21414 -1.942593  1.304554  1.074131  0.864786 -0.690940  2.138776 -3.094906  \n",
       "21415 -3.030559  0.918972 -0.509071 -0.463985  1.426476  0.929387 -0.430397  \n",
       "21416 -3.251756  1.294001  0.302334  1.666978 -0.167826  0.217958 -2.211897  \n",
       "21417 -2.897301 -0.001716  0.158579 -0.979520  0.039815  1.450755  0.442973  \n",
       "\n",
       "[17114 rows x 512 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21419, 512)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_train_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesrezgui/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)             │        \u001b[38;5;34m15,934\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m63\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">409,981</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m409,981\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">409,981</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m409,981\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NN 2: descriptions and images\n",
    "\n",
    "input_shape = X_final_train_exp.shape[1]\n",
    "\n",
    "# neurons number\n",
    "n_neurons = 512\n",
    "\n",
    "# define a model\n",
    "final_model = keras.Sequential()\n",
    "\n",
    "# Add input layer\n",
    "final_model.add(layers.Dense(\n",
    "            n_neurons, # number of neurons\n",
    "            input_dim = input_shape, # number of inputs \n",
    "            activation = 'relu' # activation faunction\n",
    "            ))\n",
    "\n",
    "# Hidden - Layers\n",
    "final_model.add(layers.Dropout(\n",
    "                    0.3, \n",
    "                    noise_shape=None, \n",
    "                    seed=None))\n",
    "final_model.add(layers.Dense(\n",
    "    256, \n",
    "    activation = \"relu\"))\n",
    "final_model.add(layers.Dropout(\n",
    "                    0.2, \n",
    "                    noise_shape=None, \n",
    "                    seed=None))\n",
    "final_model.add(layers.Dense(\n",
    "    62, \n",
    "    activation = \"relu\"))\n",
    "final_model.add(layers.Dropout(\n",
    "                    0.2, \n",
    "                    noise_shape=None, \n",
    "                    seed=None))\n",
    "    \n",
    "# Final layer\n",
    "final_model.add(layers.Dense(\n",
    "    1, \n",
    "    activation = 'linear'))\n",
    "\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=['mean_squared_error'], \n",
    "    metrics = ['mae', 'mean_squared_error']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.6821 - mae: 1.0710 - mean_squared_error: 2.6822 - val_loss: 1.2298 - val_mae: 1.0892 - val_mean_squared_error: 1.2306\n",
      "Epoch 2/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4448 - mae: 0.5327 - mean_squared_error: 0.4448 - val_loss: 1.6829 - val_mae: 1.2815 - val_mean_squared_error: 1.6847\n",
      "Epoch 3/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3243 - mae: 0.4518 - mean_squared_error: 0.3243 - val_loss: 1.7591 - val_mae: 1.3114 - val_mean_squared_error: 1.7619\n",
      "Epoch 4/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2733 - mae: 0.4171 - mean_squared_error: 0.2733 - val_loss: 1.1489 - val_mae: 1.0544 - val_mean_squared_error: 1.1507\n",
      "Epoch 5/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2330 - mae: 0.3835 - mean_squared_error: 0.2330 - val_loss: 0.7520 - val_mae: 0.8477 - val_mean_squared_error: 0.7531\n",
      "Epoch 6/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.2000 - mae: 0.3518 - mean_squared_error: 0.2000 - val_loss: 0.5310 - val_mae: 0.7076 - val_mean_squared_error: 0.5317\n",
      "Epoch 7/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1763 - mae: 0.3327 - mean_squared_error: 0.1763 - val_loss: 0.2724 - val_mae: 0.4965 - val_mean_squared_error: 0.2721\n",
      "Epoch 8/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1461 - mae: 0.2999 - mean_squared_error: 0.1461 - val_loss: 0.1854 - val_mae: 0.4028 - val_mean_squared_error: 0.1849\n",
      "Epoch 9/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1373 - mae: 0.2889 - mean_squared_error: 0.1373 - val_loss: 0.0574 - val_mae: 0.1891 - val_mean_squared_error: 0.0561\n",
      "Epoch 10/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1221 - mae: 0.2725 - mean_squared_error: 0.1221 - val_loss: 0.0522 - val_mae: 0.1718 - val_mean_squared_error: 0.0509\n",
      "Epoch 11/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1162 - mae: 0.2644 - mean_squared_error: 0.1162 - val_loss: 0.0508 - val_mae: 0.1668 - val_mean_squared_error: 0.0494\n",
      "Epoch 12/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1120 - mae: 0.2579 - mean_squared_error: 0.1120 - val_loss: 0.0499 - val_mae: 0.1620 - val_mean_squared_error: 0.0484\n",
      "Epoch 13/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1030 - mae: 0.2470 - mean_squared_error: 0.1030 - val_loss: 0.0483 - val_mae: 0.1560 - val_mean_squared_error: 0.0469\n",
      "Epoch 14/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1004 - mae: 0.2425 - mean_squared_error: 0.1004 - val_loss: 0.0461 - val_mae: 0.1442 - val_mean_squared_error: 0.0445\n",
      "Epoch 15/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0964 - mae: 0.2380 - mean_squared_error: 0.0964 - val_loss: 0.0489 - val_mae: 0.1590 - val_mean_squared_error: 0.0474\n",
      "Epoch 16/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0903 - mae: 0.2274 - mean_squared_error: 0.0903 - val_loss: 0.0475 - val_mae: 0.1507 - val_mean_squared_error: 0.0460\n",
      "Epoch 17/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0868 - mae: 0.2242 - mean_squared_error: 0.0868 - val_loss: 0.0472 - val_mae: 0.1501 - val_mean_squared_error: 0.0456\n",
      "Epoch 18/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0826 - mae: 0.2163 - mean_squared_error: 0.0826 - val_loss: 0.0499 - val_mae: 0.1588 - val_mean_squared_error: 0.0484\n",
      "Epoch 19/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0784 - mae: 0.2097 - mean_squared_error: 0.0784 - val_loss: 0.0461 - val_mae: 0.1451 - val_mean_squared_error: 0.0445\n",
      "Epoch 20/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0739 - mae: 0.2032 - mean_squared_error: 0.0739 - val_loss: 0.0463 - val_mae: 0.1460 - val_mean_squared_error: 0.0448\n",
      "Epoch 21/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0708 - mae: 0.1996 - mean_squared_error: 0.0708 - val_loss: 0.0497 - val_mae: 0.1605 - val_mean_squared_error: 0.0483\n",
      "Epoch 22/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0677 - mae: 0.1918 - mean_squared_error: 0.0677 - val_loss: 0.0458 - val_mae: 0.1352 - val_mean_squared_error: 0.0441\n",
      "Epoch 23/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0670 - mae: 0.1887 - mean_squared_error: 0.0670 - val_loss: 0.0461 - val_mae: 0.1433 - val_mean_squared_error: 0.0445\n",
      "Epoch 24/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0630 - mae: 0.1832 - mean_squared_error: 0.0630 - val_loss: 0.0476 - val_mae: 0.1507 - val_mean_squared_error: 0.0460\n",
      "Epoch 25/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0600 - mae: 0.1773 - mean_squared_error: 0.0600 - val_loss: 0.0477 - val_mae: 0.1526 - val_mean_squared_error: 0.0462\n",
      "Epoch 26/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0593 - mae: 0.1751 - mean_squared_error: 0.0593 - val_loss: 0.0456 - val_mae: 0.1414 - val_mean_squared_error: 0.0440\n",
      "Epoch 27/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0575 - mae: 0.1723 - mean_squared_error: 0.0575 - val_loss: 0.0476 - val_mae: 0.1537 - val_mean_squared_error: 0.0461\n",
      "Epoch 28/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0542 - mae: 0.1668 - mean_squared_error: 0.0542 - val_loss: 0.0467 - val_mae: 0.1447 - val_mean_squared_error: 0.0451\n",
      "Epoch 29/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0532 - mae: 0.1645 - mean_squared_error: 0.0532 - val_loss: 0.0459 - val_mae: 0.1419 - val_mean_squared_error: 0.0443\n",
      "Epoch 30/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0515 - mae: 0.1592 - mean_squared_error: 0.0515 - val_loss: 0.0482 - val_mae: 0.1567 - val_mean_squared_error: 0.0468\n",
      "Epoch 31/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0493 - mae: 0.1560 - mean_squared_error: 0.0493 - val_loss: 0.0484 - val_mae: 0.1564 - val_mean_squared_error: 0.0469\n",
      "Epoch 32/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0478 - mae: 0.1541 - mean_squared_error: 0.0478 - val_loss: 0.0475 - val_mae: 0.1527 - val_mean_squared_error: 0.0460\n",
      "Epoch 33/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0487 - mae: 0.1537 - mean_squared_error: 0.0487 - val_loss: 0.0480 - val_mae: 0.1530 - val_mean_squared_error: 0.0464\n",
      "Epoch 34/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0494 - mae: 0.1523 - mean_squared_error: 0.0494 - val_loss: 0.0457 - val_mae: 0.1406 - val_mean_squared_error: 0.0441\n",
      "Epoch 35/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0463 - mae: 0.1480 - mean_squared_error: 0.0463 - val_loss: 0.0484 - val_mae: 0.1557 - val_mean_squared_error: 0.0468\n",
      "Epoch 36/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0460 - mae: 0.1476 - mean_squared_error: 0.0460 - val_loss: 0.0453 - val_mae: 0.1309 - val_mean_squared_error: 0.0437\n",
      "Epoch 37/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0452 - mae: 0.1447 - mean_squared_error: 0.0452 - val_loss: 0.0455 - val_mae: 0.1404 - val_mean_squared_error: 0.0440\n",
      "Epoch 38/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0457 - mae: 0.1443 - mean_squared_error: 0.0457 - val_loss: 0.0464 - val_mae: 0.1437 - val_mean_squared_error: 0.0448\n",
      "Epoch 39/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0443 - mae: 0.1414 - mean_squared_error: 0.0443 - val_loss: 0.0453 - val_mae: 0.1380 - val_mean_squared_error: 0.0437\n",
      "Epoch 40/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0443 - mae: 0.1420 - mean_squared_error: 0.0443 - val_loss: 0.0461 - val_mae: 0.1446 - val_mean_squared_error: 0.0445\n",
      "Epoch 41/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0440 - mae: 0.1403 - mean_squared_error: 0.0440 - val_loss: 0.0459 - val_mae: 0.1438 - val_mean_squared_error: 0.0443\n",
      "Epoch 42/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0429 - mae: 0.1389 - mean_squared_error: 0.0429 - val_loss: 0.0489 - val_mae: 0.1593 - val_mean_squared_error: 0.0474\n",
      "Epoch 43/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0416 - mae: 0.1376 - mean_squared_error: 0.0416 - val_loss: 0.0461 - val_mae: 0.1464 - val_mean_squared_error: 0.0446\n",
      "Epoch 44/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0441 - mae: 0.1416 - mean_squared_error: 0.0441 - val_loss: 0.0460 - val_mae: 0.1456 - val_mean_squared_error: 0.0445\n",
      "Epoch 45/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0426 - mae: 0.1371 - mean_squared_error: 0.0426 - val_loss: 0.0458 - val_mae: 0.1440 - val_mean_squared_error: 0.0443\n",
      "Epoch 46/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0425 - mae: 0.1384 - mean_squared_error: 0.0425 - val_loss: 0.0476 - val_mae: 0.1538 - val_mean_squared_error: 0.0461\n",
      "Epoch 47/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0439 - mae: 0.1378 - mean_squared_error: 0.0439 - val_loss: 0.0471 - val_mae: 0.1509 - val_mean_squared_error: 0.0456\n",
      "Epoch 48/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0425 - mae: 0.1364 - mean_squared_error: 0.0425 - val_loss: 0.0455 - val_mae: 0.1415 - val_mean_squared_error: 0.0440\n",
      "Epoch 49/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0408 - mae: 0.1337 - mean_squared_error: 0.0408 - val_loss: 0.0472 - val_mae: 0.1510 - val_mean_squared_error: 0.0456\n",
      "Epoch 50/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0411 - mae: 0.1349 - mean_squared_error: 0.0411 - val_loss: 0.0472 - val_mae: 0.1521 - val_mean_squared_error: 0.0457\n",
      "Epoch 51/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0435 - mae: 0.1366 - mean_squared_error: 0.0435 - val_loss: 0.0466 - val_mae: 0.1480 - val_mean_squared_error: 0.0450\n",
      "Epoch 52/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0421 - mae: 0.1353 - mean_squared_error: 0.0421 - val_loss: 0.0504 - val_mae: 0.1648 - val_mean_squared_error: 0.0489\n",
      "Epoch 53/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0425 - mae: 0.1364 - mean_squared_error: 0.0425 - val_loss: 0.0480 - val_mae: 0.1548 - val_mean_squared_error: 0.0465\n",
      "Epoch 54/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0423 - mae: 0.1351 - mean_squared_error: 0.0423 - val_loss: 0.0468 - val_mae: 0.1448 - val_mean_squared_error: 0.0451\n",
      "Epoch 55/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0431 - mae: 0.1348 - mean_squared_error: 0.0431 - val_loss: 0.0458 - val_mae: 0.1427 - val_mean_squared_error: 0.0443\n",
      "Epoch 56/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0406 - mae: 0.1329 - mean_squared_error: 0.0406 - val_loss: 0.0473 - val_mae: 0.1521 - val_mean_squared_error: 0.0458\n",
      "Epoch 57/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0428 - mae: 0.1362 - mean_squared_error: 0.0428 - val_loss: 0.0455 - val_mae: 0.1403 - val_mean_squared_error: 0.0439\n",
      "Epoch 58/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0416 - mae: 0.1341 - mean_squared_error: 0.0416 - val_loss: 0.0500 - val_mae: 0.1636 - val_mean_squared_error: 0.0485\n",
      "Epoch 59/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0418 - mae: 0.1357 - mean_squared_error: 0.0418 - val_loss: 0.0462 - val_mae: 0.1468 - val_mean_squared_error: 0.0447\n",
      "Epoch 60/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0413 - mae: 0.1342 - mean_squared_error: 0.0413 - val_loss: 0.0474 - val_mae: 0.1523 - val_mean_squared_error: 0.0458\n",
      "Epoch 61/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0407 - mae: 0.1333 - mean_squared_error: 0.0407 - val_loss: 0.0491 - val_mae: 0.1595 - val_mean_squared_error: 0.0476\n",
      "Epoch 62/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0411 - mae: 0.1346 - mean_squared_error: 0.0411 - val_loss: 0.0475 - val_mae: 0.1522 - val_mean_squared_error: 0.0460\n",
      "Epoch 63/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0419 - mae: 0.1349 - mean_squared_error: 0.0419 - val_loss: 0.0470 - val_mae: 0.1501 - val_mean_squared_error: 0.0455\n",
      "Epoch 64/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0407 - mae: 0.1321 - mean_squared_error: 0.0407 - val_loss: 0.0474 - val_mae: 0.1525 - val_mean_squared_error: 0.0459\n",
      "Epoch 65/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0425 - mae: 0.1342 - mean_squared_error: 0.0425 - val_loss: 0.0491 - val_mae: 0.1604 - val_mean_squared_error: 0.0477\n",
      "Epoch 66/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0412 - mae: 0.1328 - mean_squared_error: 0.0412 - val_loss: 0.0490 - val_mae: 0.1589 - val_mean_squared_error: 0.0475\n",
      "Epoch 67/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0413 - mae: 0.1342 - mean_squared_error: 0.0413 - val_loss: 0.0450 - val_mae: 0.1380 - val_mean_squared_error: 0.0435\n",
      "Epoch 68/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0414 - mae: 0.1332 - mean_squared_error: 0.0414 - val_loss: 0.0450 - val_mae: 0.1377 - val_mean_squared_error: 0.0435\n",
      "Epoch 69/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0420 - mae: 0.1347 - mean_squared_error: 0.0420 - val_loss: 0.0482 - val_mae: 0.1533 - val_mean_squared_error: 0.0466\n",
      "Epoch 70/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0409 - mae: 0.1325 - mean_squared_error: 0.0409 - val_loss: 0.0471 - val_mae: 0.1510 - val_mean_squared_error: 0.0456\n",
      "Epoch 71/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0433 - mae: 0.1347 - mean_squared_error: 0.0433 - val_loss: 0.0470 - val_mae: 0.1507 - val_mean_squared_error: 0.0455\n",
      "Epoch 72/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0421 - mae: 0.1328 - mean_squared_error: 0.0421 - val_loss: 0.0481 - val_mae: 0.1553 - val_mean_squared_error: 0.0466\n",
      "Epoch 73/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0418 - mae: 0.1340 - mean_squared_error: 0.0418 - val_loss: 0.0480 - val_mae: 0.1548 - val_mean_squared_error: 0.0465\n",
      "Epoch 74/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0431 - mae: 0.1360 - mean_squared_error: 0.0431 - val_loss: 0.0457 - val_mae: 0.1439 - val_mean_squared_error: 0.0442\n",
      "Epoch 75/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0424 - mae: 0.1343 - mean_squared_error: 0.0424 - val_loss: 0.0455 - val_mae: 0.1429 - val_mean_squared_error: 0.0440\n",
      "Epoch 76/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0405 - mae: 0.1326 - mean_squared_error: 0.0405 - val_loss: 0.0475 - val_mae: 0.1530 - val_mean_squared_error: 0.0460\n",
      "Epoch 77/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0409 - mae: 0.1328 - mean_squared_error: 0.0409 - val_loss: 0.0478 - val_mae: 0.1554 - val_mean_squared_error: 0.0464\n",
      "Epoch 78/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0404 - mae: 0.1329 - mean_squared_error: 0.0404 - val_loss: 0.0503 - val_mae: 0.1655 - val_mean_squared_error: 0.0490\n",
      "Epoch 79/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0408 - mae: 0.1343 - mean_squared_error: 0.0408 - val_loss: 0.0480 - val_mae: 0.1567 - val_mean_squared_error: 0.0466\n",
      "Epoch 80/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0420 - mae: 0.1355 - mean_squared_error: 0.0420 - val_loss: 0.0455 - val_mae: 0.1428 - val_mean_squared_error: 0.0441\n",
      "Epoch 81/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0423 - mae: 0.1333 - mean_squared_error: 0.0423 - val_loss: 0.0504 - val_mae: 0.1659 - val_mean_squared_error: 0.0490\n",
      "Epoch 82/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0408 - mae: 0.1321 - mean_squared_error: 0.0408 - val_loss: 0.0511 - val_mae: 0.1683 - val_mean_squared_error: 0.0497\n",
      "Epoch 83/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0407 - mae: 0.1332 - mean_squared_error: 0.0407 - val_loss: 0.0466 - val_mae: 0.1495 - val_mean_squared_error: 0.0452\n",
      "Epoch 84/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0410 - mae: 0.1328 - mean_squared_error: 0.0410 - val_loss: 0.0464 - val_mae: 0.1494 - val_mean_squared_error: 0.0451\n",
      "Epoch 85/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0411 - mae: 0.1334 - mean_squared_error: 0.0411 - val_loss: 0.0450 - val_mae: 0.1400 - val_mean_squared_error: 0.0436\n",
      "Epoch 86/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.1327 - mean_squared_error: 0.0403 - val_loss: 0.0469 - val_mae: 0.1510 - val_mean_squared_error: 0.0454\n",
      "Epoch 87/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0406 - mae: 0.1342 - mean_squared_error: 0.0406 - val_loss: 0.0479 - val_mae: 0.1548 - val_mean_squared_error: 0.0465\n",
      "Epoch 88/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0426 - mae: 0.1350 - mean_squared_error: 0.0426 - val_loss: 0.0465 - val_mae: 0.1486 - val_mean_squared_error: 0.0450\n",
      "Epoch 89/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0408 - mae: 0.1321 - mean_squared_error: 0.0408 - val_loss: 0.0464 - val_mae: 0.1393 - val_mean_squared_error: 0.0447\n",
      "Epoch 90/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0434 - mae: 0.1367 - mean_squared_error: 0.0434 - val_loss: 0.0465 - val_mae: 0.1473 - val_mean_squared_error: 0.0449\n",
      "Epoch 91/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0412 - mae: 0.1331 - mean_squared_error: 0.0412 - val_loss: 0.0559 - val_mae: 0.1834 - val_mean_squared_error: 0.0545\n",
      "Epoch 92/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.1326 - mean_squared_error: 0.0403 - val_loss: 0.0539 - val_mae: 0.1772 - val_mean_squared_error: 0.0525\n",
      "Epoch 93/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0421 - mae: 0.1341 - mean_squared_error: 0.0421 - val_loss: 0.0477 - val_mae: 0.1546 - val_mean_squared_error: 0.0463\n",
      "Epoch 94/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0403 - mae: 0.1321 - mean_squared_error: 0.0403 - val_loss: 0.0594 - val_mae: 0.1922 - val_mean_squared_error: 0.0581\n",
      "Epoch 95/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0426 - mae: 0.1344 - mean_squared_error: 0.0426 - val_loss: 0.0612 - val_mae: 0.1966 - val_mean_squared_error: 0.0600\n",
      "Epoch 96/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0394 - mae: 0.1300 - mean_squared_error: 0.0394 - val_loss: 0.0723 - val_mae: 0.2228 - val_mean_squared_error: 0.0710\n",
      "Epoch 97/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0408 - mae: 0.1329 - mean_squared_error: 0.0408 - val_loss: 0.0567 - val_mae: 0.1842 - val_mean_squared_error: 0.0556\n",
      "Epoch 98/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - mae: 0.1329 - mean_squared_error: 0.0406 - val_loss: 0.0735 - val_mae: 0.2256 - val_mean_squared_error: 0.0723\n",
      "Epoch 99/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.1317 - mean_squared_error: 0.0400 - val_loss: 0.0520 - val_mae: 0.1687 - val_mean_squared_error: 0.0509\n",
      "Epoch 100/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0396 - mae: 0.1317 - mean_squared_error: 0.0396 - val_loss: 0.0771 - val_mae: 0.2293 - val_mean_squared_error: 0.0759\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs_hist = final_model.fit(\n",
    "    X_final_train_exp, # input\n",
    "    y_wr_train, # output\n",
    "    epochs=100, # number of iterations\n",
    "    batch_size=50, # number of observations taken to train the data - 1030 obs/50 -> there are 17 groups (observations are taken once for epoch) so model is trained 17 times in each epoch\n",
    "    verbose=1,\n",
    "    validation_data = (X_final_test_exp, y_wr_test),\n",
    "    shuffle = True\n",
    "    #validation_split=0.2,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = final_model.predict(X_final_test_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0704975],\n",
       "       [3.959582 ],\n",
       "       [3.9879913],\n",
       "       ...,\n",
       "       [3.981378 ],\n",
       "       [4.0202203],\n",
       "       [3.9855924]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_pred, y_wr_test)\n",
    "mae = mean_absolute_error(y_pred, y_wr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Regression</th>\n",
       "      <td>(SVR())</td>\n",
       "      <td>[4.265525836702388, 4.260213607671864, 4.26396...</td>\n",
       "      <td>0.131576</td>\n",
       "      <td>0.045234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  \\\n",
       "Support Vector Regression  (SVR())   \n",
       "\n",
       "                                                                  prediction  \\\n",
       "Support Vector Regression  [4.265525836702388, 4.260213607671864, 4.26396...   \n",
       "\n",
       "                                MAE       MSE  \n",
       "Support Vector Regression  0.131576  0.045234  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Regression</th>\n",
       "      <td>(SVR())</td>\n",
       "      <td>[4.265525836702388, 4.260213607671864, 4.26396...</td>\n",
       "      <td>0.131576</td>\n",
       "      <td>0.045234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>NN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  \\\n",
       "Support Vector Regression  (SVR())   \n",
       "Neural Network                  NN   \n",
       "\n",
       "                                                                  prediction  \\\n",
       "Support Vector Regression  [4.265525836702388, 4.260213607671864, 4.26396...   \n",
       "Neural Network                                                          None   \n",
       "\n",
       "                                MAE       MSE  \n",
       "Support Vector Regression  0.131576  0.045234  \n",
       "Neural Network                 None      None  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {'model name': 'Neural Network', 'model': 'NN', 'prediction': None, 'MAE' : None, 'MSE' : None}\n",
    "evaluation_metrics.loc['Neural Network'] = new_row\n",
    "\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics.loc['Neural Network', 'prediction'] = y_pred\n",
    "evaluation_metrics.loc['Neural Network', 'MAE'] = mae\n",
    "evaluation_metrics.loc['Neural Network', 'MSE'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Regression</th>\n",
       "      <td>(SVR())</td>\n",
       "      <td>[4.265525836702388, 4.260213607671864, 4.26396...</td>\n",
       "      <td>0.131576</td>\n",
       "      <td>0.045234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>NN</td>\n",
       "      <td>[[4.0704975], [3.959582], [3.9879913], [3.9595...</td>\n",
       "      <td>0.229288</td>\n",
       "      <td>0.075926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  \\\n",
       "Support Vector Regression  (SVR())   \n",
       "Neural Network                  NN   \n",
       "\n",
       "                                                                  prediction  \\\n",
       "Support Vector Regression  [4.265525836702388, 4.260213607671864, 4.26396...   \n",
       "Neural Network             [[4.0704975], [3.959582], [3.9879913], [3.9595...   \n",
       "\n",
       "                                MAE       MSE  \n",
       "Support Vector Regression  0.131576  0.045234  \n",
       "Neural Network             0.229288  0.075926  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcYklEQVR4nO3dd3xT5eIG8OckaUY3pRsKRTayKWDBAVpAQFxXQUSWoj8VrwgXB6J41Stw7xUu4OI60ctWcaIgIpuyKUPZqwi0pZQ2bdMmTXJ+f7xNSuhuT5omfb6fTz5JT05O3py2yZN3SrIsyyAiIiLyESpPF4CIiIhISQw3RERE5FMYboiIiMinMNwQERGRT2G4ISIiIp/CcENEREQ+heGGiIiIfArDDREREfkUhhsiIiLyKQw3RERE5FMYboioXlm0aBEkSYIkSdi6dWup+2VZRlxcHCRJwl133VXq/uzsbOj1ekiShCNHjpT5HOPGjXM+x/UXvV6v+Gsiorql8XQBiIjKotfrsXTpUtx8880u2zdt2oQ///wTOp2uzMd9+eWXkCQJ0dHRWLJkCf7xj3+UuZ9Op8PHH39cartara594YnIoxhuiKheGjJkCL788kssWLAAGk3JW9XSpUvRo0cPZGZmlvm4xYsXY8iQIWjevDmWLl1abrjRaDR45JFH3FJ2IvIsNksRUb00cuRIXLlyBevWrXNus1gs+Oqrr/Dwww+X+ZjU1FRs2bIFDz30EB566CGcOXMG27dvr6siE1E9wXBDRPVSfHw8EhMTsWzZMue2n3/+GTk5OXjooYfKfMyyZcsQEBCAu+66C7169ULLli2xZMmScp8jMzOz1MVoNCr+WoiobjHcEFG99fDDD+Pbb79FQUEBAGDJkiW47bbbEBsbW+b+S5YswT333AODwQAAGDFiBFauXAmr1Vpq3/z8fERERJS6DB8+3H0viIjqBMMNEdVbw4cPR0FBAX788Ufk5ubixx9/LLdJ6uDBgzh06BBGjhzp3DZy5EhkZmZi7dq1pfbX6/VYt25dqcvs2bPd9nqIqG6wQzER1VsRERFISkrC0qVLYTKZYLPZ8MADD5S57+LFixEQEIAbbrgBJ0+eBCACTHx8PJYsWYKhQ4e67K9Wq5GUlOT210BEdY/hhojqtYcffhiPP/440tLSMHjwYISGhpbaR5ZlLFu2DPn5+ejQoUOp+zMyMpCXl4fAwMA6KDEReRrDDRHVa/fddx/+7//+Dzt27MCKFSvK3Mcx980bb7yB9u3bu9x39epVPPHEE/j222859JuogWC4IaJ6LTAwEB988AHOnj2LYcOGlbmPo0nq+eefL3OG4X//+99YsmQJww1RA8FwQ0T13tixY8u9z2w24+uvv8aAAQPKXTrh7rvvxvz585GRkYHIyEgAgNVqxeLFi8vc/7777kNAQEDtC05EHsFwQ0RebfXq1cjOzi63VgcAhg0bhjlz5mD58uV49tlnAYhQNHr06DL3P3PmDMMNkReTZFmWPV0IIiIiIqVwnhsiIiLyKQw3RERE5FMYboiIiMinMNwQERGRT2G4ISIiIp/CcENEREQ+pcHNc2O323Hx4kUEBQVBkiRPF4eIiIiqQJZl5ObmIjY2FipVxXUzDS7cXLx4EXFxcZ4uBhEREdXA+fPn0bRp0wr3aXDhJigoCIA4OcHBwR4uDREREVWF0WhEXFyc83O8Ig0u3DiaooKDgxluiIiIvExVupSwQzERERH5FIYbIiIi8ikMN0RERORTGlyfm6qy2WwoKirydDG8kp+fH9RqtaeLQUREDRTDzXVkWUZaWhqys7M9XRSvFhoaiujoaM4lREREdY7h5jqOYBMZGQl/f39+OFeTLMswmUzIyMgAAMTExHi4RERE1NAw3FzDZrM5g03jxo09XRyvZTAYAAAZGRmIjIxkExUREdUpdii+hqOPjb+/v4dL4v0c55D9loiIqK4x3JSBTVG1x3NIRESewnBDREREPoXhhkqJj4/HvHnzPF0MIiKiGmGHYh/Rr18/dO3aVZFQsnv3bgQEBNS+UERERB7AcFPXZDsACajjPimyLMNms0GjqfxXHhERUQclIiIicg82S9UlWxGQcQS4ckLRw44bNw6bNm3C/PnzIUkSJEnCokWLIEkSfv75Z/To0QM6nQ5bt27FqVOncM899yAqKgqBgYHo2bMnfv31V5fjXd8sJUkSPv74Y9x3333w9/dH69at8f333yv6GoiIiJTCcFMJWZZhsliVuWRdhKmwEKb8XJjMRZXuL8tylco4f/58JCYm4vHHH8elS5dw6dIlxMXFAQBeeuklzJ49G0eOHEHnzp2Rl5eHIUOGYP369di/fz/uvPNODBs2DKmpqRU+x+uvv47hw4fj4MGDGDJkCEaNGoWsrKxan18iIiKlsVmqEgVFNnSYsdYNR06rdI8/3hgEf23lv6KQkBBotVr4+/sjOjoaAHD06FEAwBtvvIEBAwY49w0LC0OXLl2cP7/55pv45ptv8P333+OZZ54p9znGjRuHkSNHAgBmzpyJBQsWYNeuXbjzzjsrLR8REVFdYs2Nj0tISHD5OS8vD1OnTkX79u0RGhqKwMBAHDlypNKam86dOztvBwQEIDg42LnEAhERUX3CmptKGPzU+OONQbU7SFEhkHms+AcJgAw0bgNoDZU+d21dP+pp6tSpWLduHd5++220atUKBoMBDzzwACwWS4XH8fPzc/lZkiTY7fZal4+IiEhpDDeVkCSpSk1DFcpNB/xUgD4EsJoBayHgB6C2x72GVquFzWardL9t27Zh3LhxuO+++wCImpyzZ88qVg4iIiJPY7OUu5nzALNR3A6KBaTi2hh75UGkOuLj47Fz506cPXsWmZmZ5daqtG7dGqtWrUJKSgoOHDiAhx9+mDUwRETkUxhu3EmWAeNFcdu/MeCnB1TuCTdTp06FWq1Ghw4dEBERUW4fmrlz56JRo0bo06cPhg0bhkGDBqF79+6KloWIiMiTJLmq4419hNFoREhICHJychAcHOxyX2FhIc6cOYMWLVpAr9fX/skKc4Cs0wAkIKoDoNYCV88CBVeB4CZAYGTtn6OeUvxcEhFRg1bR5/f1WHPjTqbieWACIkSwAdzWLEVEREQCw4072YvEtda/ZJujWUpmuCEiInIHhht3slvFteqaUVFu6nNDREREAsONO9nKCDfOZilr3ZeHiIioAWC4cRdZLml6Kqvmhs1SREREbsFw4y7X1syUWXPDcENEROQODDfucm1/G0kq2c4+N0RERG7FcOMuZXUmBtgsRURE5GYMN+5SXrhxNEvJdtEvh4iIiBTFcOMuzpFS163sfe3PbJoiIiJSHMONuzhrbvxct0sqcQEUbZrq168fnnvuOcWON27cONx7772KHY+IiKiuMNy4S3nNUgBHTBEREbkRw427OJZeKCvcKNypeNy4cdi0aRPmz58PSZIgSRLOnj2Lw4cPY/DgwQgMDERUVBRGjx6NzMxM5+O++uordOrUCQaDAY0bN0ZSUhLy8/Px97//HZ9//jm+++475/E2btyoSFmJiIjcrYxPXnIhy0CRqfqPM+cCRQWAzQJY8l3vs1rEfYW5JU1UZfHzdx1GXo758+fj+PHj6NixI9544w3xUD8/9OrVCxMmTMB//vMfFBQU4MUXX8Tw4cPx22+/4dKlSxg5ciT+9a9/4b777kNubi62bNkCWZYxdepUHDlyBEajEZ999hkAICwsrPrngIiIyAMYbipTZAJmxnrmuV++CGgDKt0tJCQEWq0W/v7+iI6OBgD84x//QLdu3TBz5kznfp9++ini4uJw/Phx5OXlwWq14v7770fz5s0BAJ06dXLuazAYYDabnccjIiLyFgw3PurAgQPYsGEDAgMDS9136tQpDBw4EHfccQc6deqEQYMGYeDAgXjggQfQqFEjD5SWiIhIOQw3lfHzFzUo1SHLQNpBcTuyA6C+bsRUzp+A6QoQGAUEVVAz4udfvee9Rl5eHoYNG4Z//vOfpe6LiYmBWq3GunXrsH37dvzyyy945513MH36dOzcuRMtWrSo8fMSERF5GsNNZSSpSk1DLmxFgJ9B3NaHlO43owsSzV0aXfWPXQ6tVgubraSDcvfu3fH1118jPj4eGk3Zv2ZJktC3b1/07dsXM2bMQPPmzfHNN99gypQppY5HRETkLThayh0cw8Alddkdgt2wvlR8fDx27tyJs2fPIjMzExMnTkRWVhZGjhyJ3bt349SpU1i7di3Gjx8Pm82GnTt3YubMmdizZw9SU1OxatUqXL58Ge3bt3ce7+DBgzh27BgyMzNRVFSkWFmJiIjcyaPhZvPmzRg2bBhiY2MhSRK+/fbbCvdftWoVBgwYgIiICAQHByMxMRFr166tm8JWhyPcXN8c5eCGeW6mTp0KtVqNDh06ICIiAhaLBdu2bYPNZsPAgQPRqVMnPPfccwgNDYVKpUJwcDA2b96MIUOGoE2bNnjllVcwZ84cDB48GADw+OOPo23btkhISEBERAS2bdumWFmJiIjcyaPNUvn5+ejSpQseffRR3H///ZXuv3nzZgwYMAAzZ85EaGgoPvvsMwwbNgw7d+5Et27d6qDEVVTRBH6AWxbPbNOmDZKTk0ttX7VqVZn7t2/fHmvWrCn3eBEREfjll18UKx8REVFd8Wi4GTx4sLOmoCrmzZvn8vPMmTPx3Xff4Ycffqhf4aa8daUcOEMxERGR23h1nxu73Y7c3Nz6N8FceetKObih5oaIiIgErx4t9fbbbyMvLw/Dhw8vdx+z2Qyz2ez82Wg0ur9glTVLseaGiIjIbby25mbp0qV4/fXXsXLlSkRGRpa736xZsxASEuK8xMXFub9wFa0rBbjW3Miy+8tDRETUgHhluFm+fDkmTJiAlStXIikpqcJ9p02bhpycHOfl/PnzlR5frm3gcNTIqCsJN4DPNk3V+hwSERHVkNc1Sy1btgyPPvooli9fjqFDh1a6v06ng06nq9Kx/fxEHxmTyQSDwVDzQlbaLKWCyJV2EYTK28+LmUxisVHHOSUiIqorHv1UzcvLw8mTJ50/nzlzBikpKQgLC0OzZs0wbdo0XLhwAV988QUA0RQ1duxYzJ8/H71790ZaWhoAschjSEhIrcujVqsRGhqKjIwMAIC/vz+kKqzKXUqhBYAMWGyAXFj2PjZJNEmZTIDWd2o5ZFmGyWRCRkYGQkNDoVaXM2KMiIjITSTZg+0HGzduRP/+/UttHzt2LBYtWoRx48bh7Nmz2LhxIwCgX79+2LRpU7n7V4XRaERISAhycnIQHBxc6n5ZlpGWlobs7OzqvJRrDwDkFDd9BTcpfzh47iWxTENgJKDR1+y56rHQ0FBER0fXLBwSERFdp7LP72t5NNx4QlVPjs1mq9mSA/lZwGcDAUjAU8nl97v58lEg/SAw+N9Ay9IBz5v5+fmxxoaIiBRVnXDje509FKJWq2v2AZ2TDeSdBwxhQEBg+ftJFrGf5Qqg972aGyIiIk/xytFS9ZopU1wHhFe8n764j1BhHcy7Q0RE1IAw3Cgt3xFuIirezxluctxbHiIiogaG4UZpjnDj37ji/RhuiIiI3ILhRmnVbpZiuCEiIlISw43S2CxFRETkUQw3SnPU3Piz5oaIiMgTGG6U5qy5YZ8bIiIiT2C4UVqVm6VCxTXDDRERkaIYbpTGZikiIiKPYrhRkt0GmLLE7aqOljIbAbvdveUiIiJqQBhulGTKAlC8VJchrOJ99Y51MWQRcIiIiEgRDDdKcjRJGcLKXzDTQaMrWQ2cTVNERESKYbhRUv5lcV1Zk5QD+90QEREpjuFGSflV7EzswHBDRESkOIYbJZmuiGvW3BAREXkMw42S8qu4rpQDww0REZHiGG6U5Ohzw2YpIiIij2G4UZKpirMTO1w71w0REREpguFGSfmOPjeVrCvlwJobIiIixTHcKInNUkRERB7HcKOkmjZLMdwQEREphuFGKdVZV8qB4YaIiEhxDDdKqc66Ug7OcJPtjhIRERE1SAw3SqnOulIO+lBxzZobIiIixTDcKKW6E/gBbJYiIiJygypWMVClYrsBj/8m+t5UlTPcGAG7HVAxaxIREdUWw41SdIFAkx7VfExw8Q0ZsOSWhB0iIiKqMVYVeJKfHtDoxW02TRERESmC4cbTHLU3DDdERESKYLjxNHYqJiIiUhTDjacx3BARESmK4cbTGG6IiIgUxXDjaQw3REREimK48TSGGyIiIkUx3HiaIVRcF1z1aDGIiIh8BcONp/k3FteOFcWJiIioVhhuPM0Zbq54thxEREQ+guHG0xhuiIiIFMVw42lsliIiIlIUw42nGRqJa9bcEBERKYLhxtMcNTdF+UBRoWfLQkRE5AMYbjxNHwJIanG7gE1TREREtcVw42mSxE7FRERECmK4qQ8YboiIiBTDcFMf+IeJa4YbIiKiWvNouNm8eTOGDRuG2NhYSJKEb7/9ttLHbNy4Ed27d4dOp0OrVq2waNEit5fT7Zzhhn1uiIiIasuj4SY/Px9dunTBe++9V6X9z5w5g6FDh6J///5ISUnBc889hwkTJmDt2rVuLqmbca4bIiIixWg8+eSDBw/G4MGDq7z/woUL0aJFC8yZMwcA0L59e2zduhX/+c9/MGjQIHcV0/3Y54aIiEgxXtXnJjk5GUlJSS7bBg0ahOTkZA+VSCEMN0RERIrxaM1NdaWlpSEqKsplW1RUFIxGIwoKCmAwGEo9xmw2w2w2O382Go1uL2e1GdihmIiISCleVXNTE7NmzUJISIjzEhcX5+kileaoueEkfkRERLXmVeEmOjoa6enpLtvS09MRHBxcZq0NAEybNg05OTnOy/nz5+uiqNXDDsVERESK8apmqcTERPz0008u29atW4fExMRyH6PT6aDT6dxdtNrhPDdERESK8WjNTV5eHlJSUpCSkgJADPVOSUlBamoqAFHrMmbMGOf+Tz75JE6fPo0XXngBR48exfvvv4+VK1di8uTJnii+cpyLZ5oAi8mzZSEiIvJyHg03e/bsQbdu3dCtWzcAwJQpU9CtWzfMmDEDAHDp0iVn0AGAFi1aYPXq1Vi3bh26dOmCOXPm4OOPP/buYeAAoAsCVMWVaOx3Q0REVCuSLMuypwtRl4xGI0JCQpCTk4Pg4GBPF6fE222AvHTg/7YAMZ09XRoiIqJ6pTqf317Vodinca4bIiIiRTDc1BcMN0RERIpguKkvuHgmERGRIhhu6gvOUkxERKQIhpv6grMUExERKYLhpr5gnxsiIiJFMNzUFww3REREimC4qS8YboiIiBTBcFNfcLQUERGRIhhu6guGGyIiIkUw3NQXjmYpawEXzyQiIqoFhpv6QhsIqLXiNvvdEBER1RjDTX0hSexUTEREpACGm/qE4YaIiKjWGG7qE0MjcV1w1bPlICIi8mIMN/UJa26IiIhqjeGmPmG4ISIiqjWGm/qE4YaIiKjWGG7qE4YbIiKiWmO4qU84SzEREVGtMdzUJww3REREtcZwU5+wWYqIiKjWGG7qk2vDjSx7tixEREReiuGmPnGEG5sZsOR7tixEREReiuGmPvHzB9Q6cbuA/W6IiIhqguGmPuHimURERLXGcFPfMNwQERHVCsNNfcPh4ERERLXCcFPfsOaGiIioVhhu6hvW3BAREdUKw019w5obIiKiWmG4qW8YboiIiGqF4aa+YbghIiKqFYab+oZ9boiIiGqF4aa+MRSHG85QTEREVCMMN/UNF88kIiKqFYab+sa5eKYFMOd6tixEREReiOGmvtH6A9ogcTs3zbNlISIi8kIMN/VRSBNxbfzTs+UgIiLyQgw39VFwcbjJueDZchAREXkhhpv6KKSpuDYy3BAREVUXw0195Ag3Oec9Ww4iIiIvxHBTH7FZioiIqMYYbuojNksRERHVGMNNfeRslrrAifyIiIiqieGmPgqOFddF+UDBVc+WhYiIyMt4PNy89957iI+Ph16vR+/evbFr164K9583bx7atm0Lg8GAuLg4TJ48GYWFhXVU2jriZyiZqZhNU0RERNXi0XCzYsUKTJkyBa+99hr27duHLl26YNCgQcjIyChz/6VLl+Kll17Ca6+9hiNHjuCTTz7BihUr8PLLL9dxyevAtU1TREREVGUeDTdz587F448/jvHjx6NDhw5YuHAh/P398emnn5a5//bt29G3b188/PDDiI+Px8CBAzFy5MhKa3u8UrCjUzFnKSYiIqoOj4Ubi8WCvXv3IikpqaQwKhWSkpKQnJxc5mP69OmDvXv3OsPM6dOn8dNPP2HIkCHlPo/ZbIbRaHS5eAXHEgw5DDdERETVofHUE2dmZsJmsyEqKsple1RUFI4ePVrmYx5++GFkZmbi5ptvhizLsFqtePLJJytslpo1axZef/11RcteJzjXDRERUY14vENxdWzcuBEzZ87E+++/j3379mHVqlVYvXo13nzzzXIfM23aNOTk5Dgv5897yay/nOuGiIioRjxWcxMeHg61Wo309HSX7enp6YiOji7zMa+++ipGjx6NCRMmAAA6deqE/Px8PPHEE5g+fTpUqtJZTafTQafTKf8C3M3ZoZjNUkRERNXhsZobrVaLHj16YP369c5tdrsd69evR2JiYpmPMZlMpQKMWq0GAMi+Ntmdo1nKeBGw2z1bFiIiIi/isZobAJgyZQrGjh2LhIQE9OrVC/PmzUN+fj7Gjx8PABgzZgyaNGmCWbNmAQCGDRuGuXPnolu3bujduzdOnjyJV199FcOGDXOGHJ8RFANIKsBeBORnAEFl12YRERGRK4+GmxEjRuDy5cuYMWMG0tLS0LVrV6xZs8bZyTg1NdWlpuaVV16BJEl45ZVXcOHCBURERGDYsGF46623PPUS3EetEQHHeEF0Kma4ISIiqhJJ9rn2nIoZjUaEhIQgJycHwcHBni5OxT4eAPy5Cxj+BdDhHk+XhoiIyGOq8/ntVaOlGhzOdUNERFRtDDf1Gee6ISIiqjaGm/osJE5ccwkGIiKiKmO4qc9CWHNDRERUXTUON//73//Qt29fxMbG4ty5cwCAefPm4bvvvlOscA1eMPvcEBERVVeNws0HH3yAKVOmYMiQIcjOzobNZgMAhIaGYt68eUqWr2FzzFKclw5YLZ4tCxERkZeoUbh555138NFHH2H69Okuk+clJCTg0KFDihWuwfMPB9Q6ADKQe8nTpSEiIvIKNQo3Z86cQbdu3Upt1+l0yM/Pr3WhqJhKBQTHittcQJOIiKhKahRuWrRogZSUlFLb16xZg/bt29e2THQtLqBJRERULTVafmHKlCmYOHEiCgsLIcsydu3ahWXLlmHWrFn4+OOPlS5jw8ZOxURERNVSo3AzYcIEGAwGvPLKKzCZTHj44YcRGxuL+fPn46GHHlK6jA2bo+aGzVJERERVUuOFM0eNGoVRo0bBZDIhLy8PkZGRSpaLHDjXDRERUbXUelVwf39/+Pv7K1EWKksw+9wQERFVR43DzVdffYWVK1ciNTUVFovrHCz79u2rdcG8TbqxEOv+SIdWo8LwhDjlDuyoueESDERERFVSo9FSCxYswPjx4xEVFYX9+/ejV69eaNy4MU6fPo3BgwcrXUavkJplwivfHsZ7G04qe2BHn5uCq4DFpOyxiYiIfFCNws3777+PDz/8EO+88w60Wi1eeOEFrFu3Ds8++yxycnKULqNXaOTvBwC4mq/wTML6EEAbJG6zUzEREVGlahRuUlNT0adPHwCAwWBAbm4uAGD06NFYtmyZcqXzIqH+WgCAsdAKq82u7MGdnYrPK3tcIiIiH1SjcBMdHY2srCwAQLNmzbBjxw4AYuZiWZaVK50XCTX4OW/nFBQpe3DnRH6suSEiIqpMjcLN7bffju+//x4AMH78eEyePBkDBgzAiBEjcN999ylaQG+hUasQrBf9s6+aFA43jon82CxFRERUqRqNlvrwww9ht4uml4kTJyI8PBzbtm3D3XffjSeffFLRAnqTRgFaGAutuGpSuN+Ns+aGzVJERESVqVHNjUqlgtVqxa5du/Djjz/CYDAgKSkJzZs3x5o1a5Quo9dw9LtRvFNxQIS4zr+i7HGJiIh8UI1qbtasWYPRo0fjypXSH7aSJMFms9W6YN7IMWIqW+lmKf/G4rogS9njEhER+aAa1dz89a9/xfDhw3Hp0iXY7XaXS0MNNgDQyFFzo3SzlH+YuDYx3BAREVWmRuEmPT0dU6ZMQVRUlNLl8Wqhjrlu3FVzY2KzFBERUWVqFG4eeOABbNy4UeGieL+w4pqbbKVrbgzFNTeF2YC94daMERERVUWN+ty8++67ePDBB7FlyxZ06tQJfn5+Lvc/++yzihTO24QGuKlZytBIXMt2oDCnpJmKiIiISqlRuFm2bBl++eUX6PV6bNy4EZIkOe+TJKnBhpuSJRgUbpbSaAFdMGA2in43DDdERETlqlG4mT59Ol5//XW89NJLUKlq1LLlk9zWoRgQtTdmY3G/m1bKH5+IiMhH1CiZWCwWjBgxgsHmOm7rUAxwODgREVEV1SidjB07FitWrFC6LF6v0TUdihVfY4vDwYmIiKqkRs1SNpsN//rXv7B27Vp07ty5VIfiuXPnKlI4b+MIN1a7jDyzFUF6v0oeUQ2OEVMcDk5ERFShGoWbQ4cOoVu3bgCAw4cPu9x3befihsagVUOnUcFstSPbVKRsuGGzFBERUZXUKNxs2LBB6XL4jLAALS7lFOKqyYK4MH/lDuzPmhsiIqKqYI9ghTkXz1R8lmL2uSEiIqoKhhuFlcx146ZZiguuKntcIiIiH8NwozD3L57JZikiIqKKMNwozP2LZ7JZioiIqCIMNwpr5O7FMwuyAKXn0CEiIvIhDDcKc1/NTXG4sVvFMgxERERUJoYbhYUFuKnmxs8A+BUPLWe/GyIionIx3CjMrYtnOvvdcMQUERFReRhuFOZslsp3w+KZhkbimrMUExERlYvhRmHurbnhcHAiIqLKMNwozBFuTBYbzFabsgfncHAiIqJKMdwoLEivgap47dBspUdMcWVwIiKiSjHcKEylkq5ZX0rpWYq5MjgREVFlPB5u3nvvPcTHx0Ov16N3797YtWtXhftnZ2dj4sSJiImJgU6nQ5s2bfDTTz/VUWmrxm2dirl4JhERUaU0nnzyFStWYMqUKVi4cCF69+6NefPmYdCgQTh27BgiIyNL7W+xWDBgwABERkbiq6++QpMmTXDu3DmEhobWfeErEOavxWnku2+WYjZLERERlcuj4Wbu3Ll4/PHHMX78eADAwoULsXr1anz66ad46aWXSu3/6aefIisrC9u3b4efn6gdiY+Pr8siV0lJs5Sbam64MjgREVG5PNYsZbFYsHfvXiQlJZUURqVCUlISkpOTy3zM999/j8TEREycOBFRUVHo2LEjZs6cCZut/FFJZrMZRqPR5eJujZxLMHBlcCIiorrmsXCTmZkJm82GqKgol+1RUVFIS0sr8zGnT5/GV199BZvNhp9++gmvvvoq5syZg3/84x/lPs+sWbMQEhLivMTFxSn6OsrSqHgJhqv5bupQbOLimUREROXxeIfi6rDb7YiMjMSHH36IHj16YMSIEZg+fToWLlxY7mOmTZuGnJwc5+X8+fNuL6fbFs909LmxmQFLvrLHJiIi8hEe63MTHh4OtVqN9PR0l+3p6emIjo4u8zExMTHw8/ODWq12bmvfvj3S0tJgsVig1WpLPUan00Gn0ylb+Eo4JvJTvEOxNgBQawGbRQwH1wUqe3wiIiIf4LGaG61Wix49emD9+vXObXa7HevXr0diYmKZj+nbty9OnjwJu93u3Hb8+HHExMSUGWw8xW19biSJsxQTERFVwqPNUlOmTMFHH32Ezz//HEeOHMFTTz2F/Px85+ipMWPGYNq0ac79n3rqKWRlZWHSpEk4fvw4Vq9ejZkzZ2LixImeegllKqm5ccfimexUTEREVBGPDgUfMWIELl++jBkzZiAtLQ1du3bFmjVrnJ2MU1NToVKV5K+4uDisXbsWkydPRufOndGkSRNMmjQJL774oqdeQpmcHYrduXgmh4MTERGVyaPhBgCeeeYZPPPMM2Xet3HjxlLbEhMTsWPHDjeXqnYcHYpzCopgt8tQORabUgKHgxMREVXIq0ZLeYtQg6i5scuAsVDpifzY54aIiKgiDDduoNWoEKgTlWJZSs914+hzw8UziYiIysRw4yZum+uGzVJEREQVYrhxE7fNdcNmKSIiogox3LiJ22cpZs0NERFRmRhu3CQswM01NxwKTkREVCaGGzdxNEspvzJ4I3HNmhsiIqIyMdy4idubpYpMQFGhsscmIiLyAQw3buK2DsX6EEAqXjiUw8GJiIhKYbhxE0fNjeLz3EgSh4MTERFVgOHGTdy6eCaHgxMREZWL4cZN3NahGOBwcCIiogow3LhJo4CSDsWyLCt7cH8uwUBERFQehhs3cdTcWKx2FBTZlD24s88N57ohIiK6HsONm/hr1dCqxenlLMVERER1h+HGTSRJKpnrRukRU85ZitksRUREdD2GGzdy24gpDgUnIiIqF8ONGznnuuHK4ERERHWG4caNGgeKmpsMo8LLJLDPDRERUbkYbtzoxtgQAMD+1GxlD+wcCs7RUkRERNdjuHGjHs3FCt57zmUpO9eNo1nKbARsbpgBmYiIyIsx3LhRl6ah0KgkpBvN+PNqgXIH1ocAkMRt9rshIiJywXDjRgatGjc2EU1Te84pGEJUasAgaoXY74aIiMgVw42b9XQ0TZ1VuH9MaDNxnXVK2eMSERF5OYYbN0uIF+Fm7zmFw01ke3GdcUTZ4xIREXk5hhs369FcjGw6lp6LnAIFO/86w80fyh2TiIjIBzDcuFlEkA7NG/tDloF9qQrW3kR2ENcZR5U7JhERkQ9guKkDCcW1N3uV7HfjqLm5cgKwKjwDMhERkRdjuKkDjn43io6YCm4C6IIBuxW4clK54xIREXk5hps6kFA8YirlfDaKbHZlDipJQEQ7cfsyOxUTERE5MNzUgZYRgQj190NhkR2/XzQqd2COmCIiIiqF4aYOqFQSejRzzHejYNMUww0REVEpDDd1pIc75rvhcHAiIqJSGG7qiGPE1O6zV5VbRNMxHDzrDFCk4NpVREREXozhpo50bhoCrVqFzDwzUrNMyhw0IKJ4hXAZuHxMmWMSERF5OYabOqL3U6Njk2AACq4zJUlABPvdEBERXYvhpg4lxIumqT3u6HfD4eBEREQAGG7qVI/i+W52c8QUERGR2zDc1KGe8WHQqCSczMjDfqXWmWK4ISIicsFwU4fCArS4t1sTAMD7G08pc1DHLMU554FCBScIJCIi8lIMN3XsydtaQpKAdX+k41habu0P6B8GBMWI2xwxRURExHBT11pFBmJwx2gAwMJNCtXecDI/IiIiJ4YbD3i6XysAwPcHLiL1igJz3nA4OBERkRPDjQd0bBKCW9tEwGaX8d/NCtTecDg4ERGRE8ONh0zs1xIA8OWeP5FhLKzdwRzLMLDmhoiIiOHGU3q1CENC80aw2Oz4eOuZ2h0soq24zksH8q/UvnBERERerF6Em/feew/x8fHQ6/Xo3bs3du3aVaXHLV++HJIk4d5773VvAd1AkiRM7C/63izecQ7ZJkvND6YLBEKbidtsmiIiogbO4+FmxYoVmDJlCl577TXs27cPXbp0waBBg5CRkVHh486ePYupU6filltuqaOSKq9f2wi0jwmGyWLDZ9vO1u5gbJoiIiICUA/Czdy5c/H4449j/Pjx6NChAxYuXAh/f398+umn5T7GZrNh1KhReP3113HDDTfUYWmVJWpvRN+bRdvPIs9srfnBOFMxERERAA+HG4vFgr179yIpKcm5TaVSISkpCcnJyeU+7o033kBkZCQee+yxSp/DbDbDaDS6XOqTwR1jcENEAHIKirB4x7maH8gxU3HmcWUKRkRE5KU8Gm4yMzNhs9kQFRXlsj0qKgppaWllPmbr1q345JNP8NFHH1XpOWbNmoWQkBDnJS4urtblVpJaJTnnvfl4y2kUFtlqdqDASHFtYodiIiJq2DzeLFUdubm5GD16ND766COEh4dX6THTpk1DTk6O83L+/Hk3l7L67ukai6aNDMjMs2D5rtSaHcQQJq5NCq44TkRE5IU0nnzy8PBwqNVqpKenu2xPT09HdHR0qf1PnTqFs2fPYtiwYc5tdrsdAKDRaHDs2DG0bNnS5TE6nQ46nc4NpVeOn1qFJ29riVe+PYz/bj6Nkb2bQadRV+8g/o3FdUEWIMuAJClfUCIiIi/g0ZobrVaLHj16YP369c5tdrsd69evR2JiYqn927Vrh0OHDiElJcV5ufvuu9G/f3+kpKTUuyan6nigR1NEBetwKacQq/ZdqP4B/ItrbmwWwJKvbOGIiIi8iEdrbgBgypQpGDt2LBISEtCrVy/MmzcP+fn5GD9+PABgzJgxaNKkCWbNmgW9Xo+OHTu6PD40NBQASm33Nno/NZ64tSXe/PEPfLDxFB7s0RQadTWyp58/oNYBNrPod6MLdF9hiYiI6jGPh5sRI0bg8uXLmDFjBtLS0tC1a1esWbPG2ck4NTUVKpVXdQ2qsZG94vDehpNIzTLhh4MXcV+3plV/sCSJ2pvcS6JpqlFz9xWUiIioHpNkWZY9XYi6ZDQaERISgpycHAQHB3u6OKW8t+Ek/r32GFpFBuKX526FSlWNvjPv9wEyfgceWQW0usN9hSQiIqpj1fn8bhhVIl5kTGJzBOs1OJmRh7W/lz0cvlyOfjcFV5UvGBERkZdguKlngvR+GNe3BQDgnd9OoloVa/4cDk5ERMRwUw+N7xMPf60af1wyYsOxitfYcuGY66aA4YaIiBouhpt6qFGAFqNvEh2Cq1V746y54SzFRETUcDHc1FOP3dICOo0K+1OzkXyqimGFsxQTEREx3NRXkUF6jOzVDICovakSfzZLERERMdzUY0/cegP81BKST1/BnrNVCCysuSEiImK4qc9iQw34S3cxkd+7G6pQe3Pt+lJEREQNFMNNPfdUv5ZQScDGY5dx6M+cind2dijmPDdERNRwMdzUc80bB+Cerk0AANO+OYh8s7X8nQ2NxLUlF7Ba6qB0RERE9Q/DjRf428A2aBygxeELRvx12X5Ybfayd9SHAlLxr5RNU0RE1EAx3HiBpo388fHYBOj9VPjtaAZe+/73sue+UalEwAHYqZiIiBoshhsv0a1ZI8x/qBskCViyMxX/3Xy67B05HJyIiBo4hhsvMujGaMy4qwMAYPbPR/H9gYuld3KMmGLNDRERNVAMN15mfN8WeLR4Yc2pKw/gZEau6w5cX4qIiBo4hhsvNH1oe9zaJgIWmx3/WH3E9U6uL0VERA0cw40XUqskvH73jfBTS9h47LLryuGO4eBsliIiogaK4cZLtQgPwLg+8QCAf/z4B4ocw8OdHYo5kR8RETVMDDde7JnbWyMsQItTl/OxeMc5sZHrSxERUQPHcOPFQgx++NvANgCAeb+ewNV8C9eXIiKiBo/hxsuNSIhDu+gg5BQUYd6vx6/pUMxwQ0REDRPDjZfTqFXOuW8W70zFOZNO3MHRUkRE1EAx3PiAPq3CMbBDFGx2GX9bfV5sLMwG7OWsQUVEROTDGG58xKt3dUBUsA4HrqjFBtkuAg4REVEDw3DjI+LC/LH62VvQq1UU8mQ9AODt73agsMjm4ZIRERHVLYYbHxIeqMMXj/aGTS86FW87eBz3v78dZzLzPVwyIiKiusNw42PUKgkhYZEAgDhDIf64ZMRdC7bgu5QLHi4ZERFR3WC48UXFw8HfSIpBrxZhyLfYMGl5Cl746gBMFquHC0dEROReDDe+qHiW4lDkYumE3nj2jtaQJGDlnj9x97vbcOSS0cMFJCIich+GG1/kXF8qCxq1ClMGtMGSCb0RGaTDyYw83PXOVvz9+9+RbbJ4tpxERERuwHDji8pYX6pPy3D8NOkW3HljNGx2GYu2n0X/tzfifzvOwWrjfDhEROQ7GG58UTnrS4UH6rBwdA8smdAbbaOCcNVUhFe/PYy73tmKVfv+5LBxIiLyCQw3vqiS9aX6tgrH6mdvxhv33IgQgx+OpuViysoDSJy1HjN/OoJzVzh0nIiIvBfDjS8yNBLXFSyeqVGrMCYxHpue74fnB7VFk1ADrpqK8OHm07jt3xsx4fPdOJrGjsdEROR9GG580TUdiisT6q/FxP6tsPmF/vh4TAL6tY2AJAG/HsnA4Plb8PyXB3App8DNBSYiIlKOxtMFIDe4tkOxLAOSVOlD1CoJSR2ikNQhCqcu52HOL8fw06E0fLn3T3x/4CLG922BJ2+7AaH+WjcXnoiIqHZYc+OLHDU3NjNQZKr2w1tGBOL9UT2w6uk+6BUfBrPVjoWbTqHv7N8w66cjyMgtVLjAREREymG48UXaQEBdXMNSQb+bynRv1ggr/u8mfDwmAe1jgpFvseG/m0/jln9uwIzvDiP1SvWDExERkbuxWcoXSZJomspLE/1uQuNqcSjRXHVH+0hsOJaBd347if2p2fgi+Ry+SD6HVpGBuLV1BG5rG4HeLcKg91Mr+EKIiIiqj+HGV/kXhxvTFUUOJ0kSbm8Xhf5tI5F86go+2HQK205m4mRGHk5m5OHTbWeg06gwqndzTB7QGkF6P0Wel4iIqLoYbnxVGbMUK0GSJPRpFY4+rcKRU1CE7Sczsen4ZWw+fhkXcwrx6bYz+PHgRbxyVwcM6xwDqQqdmYmIyEfYioBLB4HYroDKczX5DDe+yr94rpuCq257ihCDHwZ3isHgTjGQZRmbT2Tite8O4+wVE55dth8rdqfi1bs6oG1UEEMOEVFD8Oce4LM7gbCWwF/3Vmm0rjsw3PgqN9XclEeSJNzWJgJrnrsVH24+jfc2nMS2k1dw57wtCNJr0D46GO1igtA+Jhi3t4tEVLC+TspFRERVIMtA2iEgqiOgKmesUepOYPFfgNtfAW56sux9zmwS1zFdPBZsAI6W8l3lrC/lbno/NZ69ozXWTb4NAzpEQaOSkFtoxa6zWfgi+RymrTqEW/65AS9+dRCnLufVadmIiKgc618H/nsLsPnf5e+z9T+AJRfY/VH5+5zeKK5v6Kdk6aqNNTe+qpL1pdytWWN/fDQmARarHacu5+HIJSOOpuVi15kspJzPxoo957Fy73nceWM0nrytJbrEhXqknEREDV76H8C2BeL2rv8CNz8HaHSu++SmASd+EbevnASyzgBhLVz3MecBf+4Wt2+4za1FrgzDja9yNkspM1qqprQaFdrHBKN9TLBz256zWVi46RR+PZKBnw+n4efDaejTsjGevK0lbmkdzv45RER1RZaB1VMA2SZ+Nl0B/vgO6Dzcdb+UpSX7AMCp9UDYBNd9zm0H7FagUby4eFC9aJZ67733EB8fD71ej969e2PXrl3l7vvRRx/hlltuQaNGjdCoUSMkJSVVuH+DVY31pepaQnwYPh7bE79MvhX3d28CjUrC9lNXMObTXbjrna34/sBFWG12TxeTiMj3pSwFUpMBP3+gxzixbffHrvvIMrB/sbgd0V5cn1xf+liOJqkWnq21AepBuFmxYgWmTJmC1157Dfv27UOXLl0waNAgZGRklLn/xo0bMXLkSGzYsAHJycmIi4vDwIEDceHChToueT1Xxx2Ka6JNVBDmDu+KTS/0x6N9W8Bfq8bvF414dtl+9Jq5HlO/PIC1v6fBZLF6uqhERL7HlAWse1Xc7vcS0O9lQKUBzu8Uw7kdzm0Hsk6J2e/vmiu2nd4EWC2ux6sn/W0AQJJlWfZkAXr37o2ePXvi3XffBQDY7XbExcXhr3/9K1566aVKH2+z2dCoUSO8++67GDNmTKX7G41GhISEICcnB8HBwZXu77UyTwDvJgC6YGDaeU+Xpkqu5lvwRfI5fJ58Fln5Jf80Oo0KN7cKx21tI3Br6wjEhwd4sJRERD7ih+eAvZ8BEe2AJ7cCaj/gy/HA76tELc6w+WK/b54EDiwDuo0Ghi0A5rQF8jOAsT8ALW4V++RlAG+3FrefPw0ENFa8uNX5/PZonxuLxYK9e/di2rRpzm0qlQpJSUlITk6u0jFMJhOKiooQFhZW5v1msxlms9n5s9ForF2hvYVjtJTZKCZVUtf/GYMbBWgxKak1nu7fErvPZmHdH+lY90c6/rxagPVHM7D+qKjNaxbmj1vbhGNop1jcdEMY++gQEVXXn3uAvYvE7aFzSz4jek4Q4ebgSmDAG2Lb79+K6+5jxDDxVneIsHPy15Jwc2azuI7u5JZgU10ebZbKzMyEzWZDVFSUy/aoqCikpaVV6RgvvvgiYmNjkZSUVOb9s2bNQkhIiPMSF1fzdZa8ij4EQPGHvhsn8nMHP7UKfVqG47VhN2LLC/2x5rlb8PygtujdIgwalYTULBMW70jFyI924C8fbMeGYxnwcAUkEVH9J8tiZNT2d4GvJwCQgS4jgfi+Jfs07yP61RSZgAPLgcNfA9YCILwt0LSn2KdV8efttf1uTm8Q1/WgSQrw8tFSs2fPxvLly7Fx40bo9WVPCjdt2jRMmTLF+bPRaGwYAUelBgyhItiYrgCBkZ4uUY1IkoR20cFoFx2Mif1bIc9sRfKpK1h/JB3f7L+AfanZGP/ZbnRuGoKJ/VvhtjYRXLyTiOhaxkvA+jeAU7+JNQcd/BsDA9503VeSgJ6PAT9NFR2LtYFie/fRJZPy3dAfgASkHxbHDooWfXAAoEU/N7+YqvFouAkPD4darUZ6errL9vT0dERHR1f42LfffhuzZ8/Gr7/+is6dO5e7n06ng06nK/d+n2YIKwk3PiJQp8GADlEY0CEKUwa2wUebT2PxjlQc/DMH//e/vdCqVbixSTB6NGuEHs0bISE+DBFBDfT3T0QEAN88UdJspDGImpob+gMd7wcCI0rv33kE8Ovfgczj4meVBuj8UMn9AY2BJt2BC3vFkPBmiUDOeUDlBzRPdPvLqQqPhhutVosePXpg/fr1uPfeewGIDsXr16/HM888U+7j/vWvf+Gtt97C2rVrkZCQUEel9UKN4kUP9/VvAKO/BbT+ni6RoiKD9Jg+tAOevK0lPtl6Biv3nEdmngX7U7OxPzUbH289AwDoEheKO9pF4o72kegQE8w+OkTUcGQcEcFGUgEjV4g+Mn6VLH+jDxYBZ88n4ue2g0uHoFZJItyc/BWwFvdrjesNaOvHgA+PN0tNmTIFY8eORUJCAnr16oV58+YhPz8f48ePBwCMGTMGTZo0waxZswAA//znPzFjxgwsXboU8fHxzr45gYGBCAwM9NjrqJcGvgl8tkcM61s5Bhi5zCs6FldX40AdXrizHZ4f1BapWSbsPXcV+1KvYs/ZqzialosD57Nx4Hw25q47jpgQPe7qHIO/9GiKdtE+PFqOiHzP5ePAZ4NFN4Nuj4gAEhBe8WN2fSiu2w0F2gys+nP1fKwk3HQrYyRyqyRg0z+BUxvEoBXA47MSX8vjQ8EB4N1338W///1vpKWloWvXrliwYAF69+4NAOjXrx/i4+OxaNEiAEB8fDzOnTtX6hivvfYa/v73v1f6XA1mKLhD6k7gi3tEh7BOw4H7/lv+omg+KMNYiN+KR1ptPZGJgqKSGTY7NgnGX7o3xdDOMYgM4kKeRFTPffMUcGBpyc8qP1GrkvAo0LJ/6f0LsoG5xZ2Dx/4ItLiles+3YSaQfxkY8rbox3ktuw341w1AYbaoFZLtwGPrgLhe1X1VVVadz+96EW7qUoMLNwBw/Bdg+UgxLXav/wMG/9Ojq7V6SmGRDZuPX8aqfRew/mg6imwlf/qNA7RoGRmIVpGBaB0ZiC5xoegYGwKtpuEEQSKqx3LTgP90BOxFwC1/E52DL+4vuf/ud8RQ7WslvwesfRmI7AA8tV35933HnDgAoA0CXjwLqN3XIOQ189xQHWkzELh3IbBqglgUrTAH6DoSaN7XJ5upyqP3U2PgjdEYeGM0svIt+OHARXy1908cupCDK/kWXDmThV1nsq7ZX4XuzRqhZ3wYerUIQ+emIQjSN5zzRUT1yO6PRbCJuwm4Y4a4pB0Sw7oPLgd+flG8pzduKfa324Fdxat393rcPV9oWyWVhJv4m90abKqLNTcNyc7/Aj+/UPKzPgRocyfQdoiYlEkX5LmyeVC+2YrTl/NxIiMXJzPycDw9F3vPXcVVU5HLfpIEtIoIRNe4UHSJC0XvFmFoFRnIDspE3kiWxQifzBNilevME8DVs8CN94r+LPWJxQT850axVuDwL4AO95TcZ7cDX9wNnN0CxHYHHvtFfGk9/guw9EHxPj/liHs6+uamidmKAeDOfwI3Pan8c1yDzVIVaNDhBhBrfxz6Cjj2M2DKLNmu8hPJu82dQNs7Pb6iq6fZ7TJOXs7DrjNZ2H02C3vOXsWF7IJS+0UF69C3VThuaR2Ovq3C2XenvpJlYMscIOsMcNsLQKPm7n2+ogLgzBbRwVLDqQjcxmoBts0D9n4OtL8LuPWFqs2Oa7cDX40Tq1+XIgEjFovj1Rd7PgV+nAyENgee3V+6/0vOn8AHfUSt/K3PA7e/Aiz+ixjJlPgMMOgt95Xti3uA87uBp7e7/XOD4aYCDT7cONhtwPldwLHVwNHVQNZp1/ujOgFdHwY6PVj2PAhlsZpr9kZut5X+Z62ILItZMwOjqt9BrhYu55px4Hw2Us5nY1/qVew9dxVmq+vq5TeEB6BnfBh6tghD7xZhaNrI4Js1O3kZQECEd/TdkmVg3Qxg+wLxs5+/WCTwpqfd0yxrtwOL7xNfJFreDoxcXvX/i7wMwFoIhDarXRn+3Cu+yRtCxe8pIFL8H4c2947fWVWk7gB+mARcPlqyTRcM3DwZuOkpwM9Q/mN3fACseQmQ1EDjVkB4a3GdfQ74/RvxNzL+ZyC2q9tfRqXsduC9XsCVE8Cds8VrK8vhVcBX40Xn3rvfAb6bCEACnt0HhN3gvvJZTKLDcmWjthTAcFMBhptyZJ4Ejv8MHF8rVoCVi0cVqTRA64Ei6LQdUnYIkWXx7Wn9m0Czm4D+012n8y7PmS3Ar6+J6uB73nWtai2PrQj4/lkxYkClAf5vCxDVoVovVSmFRTbsPXcVW05kYuvJy/j9ohHX/jf1VR1CJ+0lBAcYEBJgQGiAAaHBgTA0647IFp0QE+oPtaqGHzTmXDFzaF1/UMmy6KC4432g1QDgLx8BhkZ1W4bq2vQvYEPxN9eojmJWVQCIvBEYNk/50R07PwR+fr7k57ZDgeGfVxykLqYAye+KD1a7VYSiPs+Kqeyr8zs+lwxs/pfobFqW5n2BR76u+INfCbIs/kY1OkCtVfbvtCAbWP+6qM0ARHjr81fg0JeiDwoABDcBkv4OdB5e+vEZR4H/3grYzGJNpZ6Pldxns4qmnFO/AUExwIT1QEgT5cpeE47mJV0wMOWPirsPOBa4dGg9CBi10v1lrCMMNxVguKkCU5boJJayVEzS5BB/C3D/R0BwTMk2WQbWvQpsf8f1GC1vB/q/AjTtUfr46X+I2S9PrHXdnvQ60HdS+W+EFhPw5TjXxzXtBTy6tvrD2+12McQx50/x7dbRCa8sJ38VQ+p7PiamGS9HjqkIe85lYdeZK2h9eB4eMK0od9+rciD2y21wSn8jLMHNEe6vQmODCmF6CSEBBgR3GYbwyJiya312fAD88oqY4+Le96vxomvJbgdWTy5ZbA8Q3wgfWgZEtqv+8fIyijs8yiJ0RHcCGrWo3u9SlgFLvhiOqgsqXlPtGo7RIgAwaJb41puyVJy/giwAEpAwHrjjNfF3UBV2O2DOKTvUZZ4AFt4ipl7o9ghw8EvxIdrpweJpGK75cmC3ib+t7e+IWhYnCUDx23J0J6DPJNEnztCo9P+GLAP5mWLUzPYFJceR1ECbQWJ4bl6G2Cf3oghO3ccCdy+o2mstuCoCl8YgajYatwT8y16kGAXZYn2hE78CJ9cBeY6Z5yVAoxeBqt0QYOBbVT/X+VeAP74t6Rdz5aSoXZGLa0y7jRaLO/qHid/LoZXiS5bxT3F/76dEk4zjvFstwMd3AGkHRTgf9WXpc1qYA3wyCLh8RJz/8WsAXQ3mUCsqBC7uE18WU3eI2X7jbxZlbnZT1QPf53cDZzZVrXmp0AgsvFmcI0AEWcc6UD6A4aYCDDfVdPkYkLIE2PUxUJQP+IeLN+nWSeJbzg+TgJTFYt/+04HcS8C+L8SbKCAWWvNvLN7Y/PzFt7mjP4o3J0ktPlgAMRIAEEMZr12h1sGUBSwdDvy5W7xR3jlbfEBZ8oChc8RKthWxWcWbZMpS4OoZIOeC+NBxuGmiGH1w7cydNivw2xvAtvniZ78AUeWdOLH82Z7tNmD1FGcAyGs+APk2NQrNZhSaLVCZs9HMfAI6WCos7kU5DH/D32CK6IobIgLRvLE/IgN16H3+I7T8/ZogOfx/QIe7K37tSrBZge+fKf5WKIlmnf2LRYdMbSBw/4dikrCqsNuAvZ+JmbMLc1zv8/MHYroCt04VH+ilylEkOsanLBHhtOBqyd+apAJiuogZWFvcKvrX/DRV3Nd/uuhr45B/RTRVOf52A6PE39SN91X8oXN2mxiVkn4Y6PsscPurJX+rNivw6UDxheCG/sAjq4ATvwArRhWHijHAXfPFB96hr0RocKzzI6nFVPiJz4gP/uT3gf3/E9X9Dtog0aehUXPx/3TllLiYrzmHKj9Ry3rzZCCshWvZT/0G/O9+ALIYPdl1ZPmvEwDyLouOqhl/uG43hIlaDbVG1J6qNIDNAlw6WFLjW5GgWFFTW9bv10GWrwuh1wlvK/7vy2qWLioEtv4H2DRb/Nx2qKhh1AaIv7ktc8RreDq5/C8rV8+JEJR/WXxRa3+3+PuSVCIoNe0pmrLKkn1e/I2cXCfOS1katxZrNXUZWfG6f2mHRFiR1MCklKo1V6buBD6/C4hoCzyx2afmNWO4qQDDTQ1lnhQd8BzVvn2eFf10jv4o/vHueVe8qQJixMGmf4kPQsc3rOu1v1t8Ww5vJX7esRBYO03sf0M/4PYZIkwVGgGzEdg6D8g8BuhDgYdXAs16l4z+0gUDE3e51ig5WEziQzj5HSA71fU+SSU+1HIviZ8j2osP6ZjOYhTAV48C57aJ+8JaiqUsgJIq744PuL5xWM3AqseLOylKwF3/KQlv17JaYLt4AMYTW2E7mwx73mUU2NUosKmQb5UQYz6DWDkdFlmNN6xjsNgmvnm9olmMCZqfAQAp9hvQVXUalxGKx4PehyGoMSKCdIgJ1SMmWI+YUANiQwyICNIhLEBbvfl6ZNn1A95WJF7X79+I3/X9HwKdHhC1AV+OK6ktSHhUnCdtgAg8ukDRZBAYJS4arWh++XGy+IAHRBiJ7izCQsYR0d/Eoe1Q8U3V8SF9ZjPw0/OufSwcVJqSkHO9vpNErWBZoeXsVuCH50R/BkA0wQ55u3SH45w/RRg6/LXr9iYJwAOfiv0dzV+6EPHB6WjOOLwK+Pox8bft39h1rTd9iPgm3/tJIPS6BX1NWcDuT8SXhZzr/nZdSEBInKip6Tup9HGutXE2sHGWqIl5/Lfym3Rz00SNQeYx0V8nsp0IUsYLFZQDInS0HiAuTRJE2CkqFL/XrFPA6qkl/0cJj4pFG6+vFck8If5GHH9XEe3Fl6nGrUougVGV13wcXiWaaWxmILYbcPMU4Mux4vdQlS8F53eLkHDt36SDpBJfqPpNK6nJkmWxivbPL4j3LECcu+aJQLM+opbzyHeiXI7QqjEAt0wR76fXL4lgvAR897QIpTfeDzz4WcXlvVbOheKaTN/6jGO4qQDDTS0UFYpvUrs/Ktmm1gEPLhLVzde7cgq4sE9U0RcViH9oW5H4JtS0jDXBjq0RgaIov+znD4oFRq8CItuLn+024JMB4pty+7uBEf8r2bcwR4SfHR+UfPPzbywmMYy/GQhpCgTHFg+ZXAt89wyQnyG++fb+P+DgSvGzNqikP9Dhr0VzWs55cTx9KBB1o5ggK7I9cOQHUS2v1ormuxvvrd75dZbdCNu3T0N99AcAwNHIwcgtUqHn1dUAgDnqx/Bxwa34UfMSWqouYYW1H160PlHmoTSwoo30J3rpziJBcxaR6lycCrkJqTGDEBIWiahgHUL9tQjQSIi6vBURR/4HQ+pGQO0HyRFQZLsIhio/8UF+7YeCrQhYO13Mn1QZ/3Dxu5DtIpDe/qpo6nM0Gdht4m9m7yJxPLtV/H31eUbUwjjm0/BvLB4b10v8DgyhosYn95Lox3Vms6jGzzkvQsOdsyv+ILSagS1zga1zS75pBxR3vm3UXJT14IriD6TiZqymvcS3c3OOCDM3TxKzudqt4nd/fV+P/UvEBxUgagDbDQE6/gVoeYcIfZUpKhC/g6vnxJeHonwRJBu3EuGvqn1o7DYxiub0BlF78MSG0n04jBeBz4eJJqDgJsDYH0qabS354ndkyhTNQHarCDCyvbhZMb7i57fkA7++XvL3EhglyqEPKW6qkkTTks0iPvj7vSRqSmva8Tt1J7DsIdfany4PA/d9ULXHn9kiliCwFYlzJ9tFE+j5neJ+Qxhwx6tAu7tEje0R8T+Lpj2Bu+aJ94fr//bMuSLg7P2sZBK+0ObAoJmi9jMvQ/Rh3POpCFaSGpjwq1iosoFjuKkAw40C/vheNFHIMvDQUmVHLF06CHz/V/EPrg8Wb7y6YPEt+NYXSn8rTTssOgfKNlGW+FtEqEl+V7wJAeKNo89fga6jym9Oys8UHZWPrS7ZFtlBfMNz1C4B4kNmxwei2tvx7exafgHAQ0vKngq9OmRZvIZ1r5VU9Usq4J73gK4Pw26XkXdiK4KWDYMEGdv6foLfdd1wKacQl7ILEZy5Dw8aP0cn+1HopaJSh7fIamy0d8V3tr5oKl3GKPWvaKa6XG5xiiQ/LGn+D6Q2vhX+WjUMWrW49hO3m2X8hsi0LZCK8iEV5UNlLYCmKA8GSxb05stQ2UvKIHd6ENLAt4CgqPJff8ZRYM2LYsSRg6QCEh4Dbp9eeSdmWRYBt6p9OwCxbs9PfytZPfl6zRLF7N4xXcTPV8+JGpk/d5fs0+Ee4MHPyw5TpzeJv8lWSZ5dXDA/U/QLyr0oagQGzRQ1X2qNqC1a/BfRdBsSJ4LN9c1bSji9SXyhKK9GqlWSaHZSYmjxlVPAkgdFjVFIM+CpraX7ZlXX6Y0i3DpqESW1+D9VaURtTt/nKp/QTpZFYP/l1ZIasdjuxTWYxdNOxN0kwlP8zbUrr49guKkAw41CzLnim0x1PjzcZd1r4puOf7h4gym4KraHtwFuexHocG/VZs6UZdGEtWGm6A8w+J/lfwhZzaI/UsYfQPrv4tpuFc1pZXWirqmzW8UU54XZwF8+KV2VvnqqqEkLbS6aQsx5YgTaNSMm7LpgFEZ0RnZoRxjtekSk/oTGecdLPZURAVgl98NSy60wQY8AFCAAhQiUCnDc3hRpqML8IWWQYEco8hAlZcMMP5yRRfOhJImus35qFQxaNfQaNfR+Kuj91NBpVNCpVehjTcZw4yLkqRvh68iJSPdvA7VKBY1KgkYtwU+tgrr4tkYlQaNSwU8tQaMW+6gkCWqVBJUESJIEWZZhttphsdlhLrKjyGaHJAFqSYJKJY7hb89HpO0SworSEGa+gEDLZZiieiD3hrug81M7n9Nml2G1mhGx621EHvwARf5RSB2+DrqQCPhrNdD7qaC6JuTIMmCXZdhkGXa7DJtdhl0GVBKgUamgUgFqlQRZBopsdlisdpitooyy81wKapVUHDA1MPipqz/qLnUnsGhIuU15tpDmuHTvl7jqF408sxUBOjWC9X4INvghSK+Bn1qBfhyWfFEDUnBVBFHHpWlPMTJTyRFWpizRvNd+WMWDB6rDViSaDTfMFDV4Ee2Km7W7VO84lnzxZWnbgpJ+gE17ipDU8nbfGbqvAIabCjDc+CCLCfggUVTXA6Ka+7YXRQfN6syfU19VNI+EORd47yYxOiT+FtGnxZIr7uv2iBhp07hV6U6F6X+I6v8jP4imnR7jRDOJ1h9Wmx1Z+RZk5JpxOc+My0YzjIVFMFlsMFlsKLBYYbLYUGi1o8BiQ2GRDQVFNlhtdmg1KvipxUWjkpBbaEVmnhmZeWYYC8vpE+MDmktpMMr+uArPvKfoNCpoNSpo1SqX0Ge1ybDYREAqstqLgxVgk2XcL23Ay5qlCIIJGqmkb9zv9uaYYJmKSxWEWa1ahDGNSiXCWfHz+akkqNUS/FQqqFQS7LIMFIe6awOaJEnOoGaTRdCz2WVY7cXBT5Zhs4lrWYYzzGrUKudzi2NJzpDseIzVLsMulxzLESrtMpxB11FejUpy/s1q1Sr4aVRirFpxee3F58teXA6bLI6tVasQqNMgQKdBtDoP7Yr+wEFDAvJtGhRa7TAX2WCXZUiSeD5HyC0osqHAIv5fTBYbZBkI0Ika0BvUl3GnZS0OaTpii70L8otsyCu0wmK1w8/xf6WS4KcR/1uO/zNHmFdL4hypJPG61NdfJMn5e7AXnxO/4pBs8NPAoFVBr1HDYrOjsMiGwiJxXWSzw1782uXi8wEUfzmRxO9ApZLgp5agVauc57NZmD/G9olX7G8cYLipEMONj7q4X/SbaHeX6OzqC6Gmqk6sA5Y8UPJzbHfRKVbJGiQFWKx25JmtLh8ckAGz1Q6zteTNtKDI5qy1sBTfV2STYbXZYS3+AHTetskostthtYkPxyKb3WWb43kcb8qSBGcIcLwJAxAfrsU1KhabCG35xUEu32xzlsFSXJNSZLM7A0RJkLDDVPyhZblucseaUBWX1U8taoDkawKC1Saj0GqDcu/eMjSwQQMbCqEFICFAq0awwQ/+WjUKLDYYC63IM/tuQCVldW8WilVPV2G+s2rgwpnU8MR2c+1Q3JC0HiBGyRxdLa67PlIvh39qNSqEVaXzrA+w2uylZq8GxDd4lUo0g6lVEiRJKqmpKK69kCQU18BU/DuUZRmFRXaYimvSiooDn8Uqrm12u+u3e5XK+c1eXdxk52jxcARNGaKZMFivKfP5rTYRUE0Wm7O8Nll2hkurvSR02uyyqLVQScW1NY5yi+dxBDO1ClCrVMVNg6I2SK2Cs5wSJOdxRbCUnTUpgOw8nqMmRlVcg+FoalRJ4rYkwaVGx1FOi81W3PwnO0Opo7ZFKm7OVEslTZuSJAK5ySzCXr7ZioIiUWup91NBpxHNqo4mRntxbQ8gFu/1d/ZXEx+/BUUiQDt+j3o/tbNWKEivgVatgtUuyucI1o7bVlvJORF/QyVB/9q/KVtxbZajpsvx2qw22VmLJGprbMWvQ118Ka4pK379apXk8ot0/B4dXziKbHZYissUE+LZpWhYc0NERET1XnU+v+vf1zsiIiKiWmC4ISIiIp/CcENEREQ+heGGiIiIfArDDREREfkUhhsiIiLyKQw3RERE5FMYboiIiMinMNwQERGRT2G4ISIiIp/CcENEREQ+heGGiIiIfArDDREREfkUhhsiIiLyKRpPF6CuybIMQCydTkRERN7B8bnt+ByvSIMLN7m5uQCAuLg4D5eEiIiIqis3NxchISEV7iPJVYlAPsRut+PixYsICgqCJEmKHttoNCIuLg7nz59HcHCwoscmVzzXdYfnuu7wXNcdnuu6o9S5lmUZubm5iI2NhUpVca+aBldzo1Kp0LRpU7c+R3BwMP9Z6gjPdd3hua47PNd1h+e67ihxriursXFgh2IiIiLyKQw3RERE5FMYbhSk0+nw2muvQafTebooPo/nuu7wXNcdnuu6w3Nddzxxrhtch2IiIiLybay5ISIiIp/CcENEREQ+heGGiIiIfArDDREREfkUhhuFvPfee4iPj4der0fv3r2xa9cuTxfJ682aNQs9e/ZEUFAQIiMjce+99+LYsWMu+xQWFmLixIlo3LgxAgMD8Ze//AXp6ekeKrHvmD17NiRJwnPPPefcxnOtnAsXLuCRRx5B48aNYTAY0KlTJ+zZs8d5vyzLmDFjBmJiYmAwGJCUlIQTJ054sMTeyWaz4dVXX0WLFi1gMBjQsmVLvPnmmy5rE/Fc19zmzZsxbNgwxMbGQpIkfPvtty73V+XcZmVlYdSoUQgODkZoaCgee+wx5OXl1b5wMtXa8uXLZa1WK3/66afy77//Lj/++ONyaGionJ6e7umiebVBgwbJn332mXz48GE5JSVFHjJkiNysWTM5Ly/Puc+TTz4px8XFyevXr5f37Nkj33TTTXKfPn08WGrvt2vXLjk+Pl7u3LmzPGnSJOd2nmtlZGVlyc2bN5fHjRsn79y5Uz59+rS8du1a+eTJk859Zs+eLYeEhMjffvutfODAAfnuu++WW7RoIRcUFHiw5N7nrbfekhs3biz/+OOP8pkzZ+Qvv/xSDgwMlOfPn+/ch+e65n766Sd5+vTp8qpVq2QA8jfffONyf1XO7Z133il36dJF3rFjh7xlyxa5VatW8siRI2tdNoYbBfTq1UueOHGi82ebzSbHxsbKs2bN8mCpfE9GRoYMQN60aZMsy7KcnZ0t+/n5yV9++aVznyNHjsgA5OTkZE8V06vl5ubKrVu3ltetWyffdtttznDDc62cF198Ub755pvLvd9ut8vR0dHyv//9b+e27OxsWafTycuWLauLIvqMoUOHyo8++qjLtvvvv18eNWqULMs810q6PtxU5dz+8ccfMgB59+7dzn1+/vlnWZIk+cKFC7UqD5ulaslisWDv3r1ISkpyblOpVEhKSkJycrIHS+Z7cnJyAABhYWEAgL1796KoqMjl3Ldr1w7NmjXjua+hiRMnYujQoS7nFOC5VtL333+PhIQEPPjgg4iMjES3bt3w0UcfOe8/c+YM0tLSXM51SEgIevfuzXNdTX369MH69etx/PhxAMCBAwewdetWDB48GADPtTtV5dwmJycjNDQUCQkJzn2SkpKgUqmwc+fOWj1/g1s4U2mZmZmw2WyIiopy2R4VFYWjR496qFS+x26347nnnkPfvn3RsWNHAEBaWhq0Wi1CQ0Nd9o2KikJaWpoHSundli9fjn379mH37t2l7uO5Vs7p06fxwQcfYMqUKXj55Zexe/duPPvss9BqtRg7dqzzfJb1nsJzXT0vvfQSjEYj2rVrB7VaDZvNhrfeegujRo0CAJ5rN6rKuU1LS0NkZKTL/RqNBmFhYbU+/ww35BUmTpyIw4cPY+vWrZ4uik86f/48Jk2ahHXr1kGv13u6OD7NbrcjISEBM2fOBAB069YNhw8fxsKFCzF27FgPl863rFy5EkuWLMHSpUtx4403IiUlBc899xxiY2N5rn0cm6VqKTw8HGq1utSokfT0dERHR3uoVL7lmWeewY8//ogNGzagadOmzu3R0dGwWCzIzs522Z/nvvr27t2LjIwMdO/eHRqNBhqNBps2bcKCBQug0WgQFRXFc62QmJgYdOjQwWVb+/btkZqaCgDO88n3lNp7/vnn8dJLL+Ghhx5Cp06dMHr0aEyePBmzZs0CwHPtTlU5t9HR0cjIyHC532q1Iisrq9bnn+GmlrRaLXr06IH169c7t9ntdqxfvx6JiYkeLJn3k2UZzzzzDL755hv89ttvaNGihcv9PXr0gJ+fn8u5P3bsGFJTU3nuq+mOO+7AoUOHkJKS4rwkJCRg1KhRzts818ro27dvqSkNjh8/jubNmwMAWrRogejoaJdzbTQasXPnTp7rajKZTFCpXD/m1Go17HY7AJ5rd6rKuU1MTER2djb27t3r3Oe3336D3W5H7969a1eAWnVHJlmWxVBwnU4nL1q0SP7jjz/kJ554Qg4NDZXT0tI8XTSv9tRTT8khISHyxo0b5UuXLjkvJpPJuc+TTz4pN2vWTP7tt9/kPXv2yImJiXJiYqIHS+07rh0tJcs810rZtWuXrNFo5Lfeeks+ceKEvGTJEtnf319evHixc5/Zs2fLoaGh8nfffScfPHhQvueeezg8uQbGjh0rN2nSxDkUfNWqVXJ4eLj8wgsvOPfhua653Nxcef/+/fL+/ftlAPLcuXPl/fv3y+fOnZNluWrn9s4775S7desm79y5U966davcunVrDgWvT9555x25WbNmslarlXv16iXv2LHD00XyegDKvHz22WfOfQoKCuSnn35abtSokezv7y/fd9998qVLlzxXaB9yfbjhuVbODz/8IHfs2FHW6XRyu3bt5A8//NDlfrvdLr/66qtyVFSUrNPp5DvuuEM+duyYh0rrvYxGozxp0iS5WbNmsl6vl2+44QZ5+vTpstlsdu7Dc11zGzZsKPM9euzYsbIsV+3cXrlyRR45cqQcGBgoBwcHy+PHj5dzc3NrXTZJlq+ZqpGIiIjIy7HPDREREfkUhhsiIiLyKQw3RERE5FMYboiIiMinMNwQERGRT2G4ISIiIp/CcENEREQ+heGGiBq8jRs3QpKkUmtnEZF3YrghIiIin8JwQ0RERD6F4YaIPM5ut2PWrFlo0aIFDAYDunTpgq+++gpASZPR6tWr0blzZ+j1etx00004fPiwyzG+/vpr3HjjjdDpdIiPj8ecOXNc7jebzXjxxRcRFxcHnU6HVq1a4ZNPPnHZZ+/evUhISIC/vz/69OlTavVuIvIODDdE5HGzZs3CF198gYULF+L333/H5MmT8cgjj2DTpk3OfZ5//nnMmTMHu3fvRkREBIYNG4aioiIAIpQMHz4cDz30EA4dOoS///3vePXVV7Fo0SLn48eMGYNly5ZhwYIFOHLkCP773/8iMDDQpRzTp0/HnDlzsGfPHmg0Gjz66KN18vqJSFlcOJOIPMpsNiMsLAy//vorEhMTndsnTJgAk8mEJ554Av3798fy5csxYsQIAEBWVhaaNm2KRYsWYfjw4Rg1ahQuX76MX375xfn4F154AatXr8bvv/+O48ePo23btli3bh2SkpJKlWHjxo3o378/fv31V9xxxx0AgJ9++glDhw5FQUEB9Hq9m88CESmJNTdE5FEnT56EyWTCgAEDEBgY6Lx88cUXOHXqlHO/a4NPWFgY2rZtiyNHjgAAjhw5gr59+7oct2/fvjhx4gRsNhtSUlKgVqtx2223VViWzp07O2/HxMQAADIyMmr9Gomobmk8XQAiatjy8vIAAKtXr0aTJk1c7tPpdC4Bp6YMBkOV9vPz83PeliQJgOgPRETehTU3RORRHTp0gE6nQ2pqKlq1auVyiYuLc+63Y8cO5+2rV6/i+PHjaN++PQCgffv22LZtm8txt23bhjZt2kCtVqNTp06w2+0ufXiIyHex5oaIPCooKAhTp07F5MmTYbfbcfPNNyMnJwfbtm1DcHAwmjdvDgB444030LhxY0RFRWH69OkIDw/HvffeCwD429/+hp49e+LNN9/EiBEjkJycjHfffRfvv/8+ACA+Ph5jx47Fo48+igULFqBLly44d+4cMjIyMHz4cE+9dCJyE4YbIvK4N998ExEREZg1axZOnz6N0NBQdO/eHS+//LKzWWj27NmYNGkSTpw4ga5du+KHH36AVqsFAHTv3h0rV67EjBkz8OabbyImJgZvvPEGxo0b53yODz74AC+//DKefvppXLlyBc2aNcPLL7/siZdLRG7G0VJEVK85RjJdvXoVoaGhni4OEXkB9rkhIiIin8JwQ0RERD6FzVJERETkU1hzQ0RERD6F4YaIiIh8CsMNERER+RSGGyIiIvIpDDdERETkUxhuiIiIyKcw3BAREZFPYbghIiIin8JwQ0RERD7l/wGXwM20TQlPowAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise NN\n",
    "\n",
    "# Plotting Loss And Root Mean Square Error For both Training And Test Sets\n",
    "plt.plot(epochs_hist.history['mae'])\n",
    "plt.plot(epochs_hist.history['val_mae'])\n",
    "plt.title('MAE')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.plot(epochs_hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('4.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
