{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71b62231-ffba-43ba-a846-b5aea7f03dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dce042a7-a776-455b-b74f-fdc516eb6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from rake_nltk import Rake\n",
    "\n",
    "# df = pd.read_csv(\"English_fiction_pre_PCA_3.csv\")\n",
    "# df = df.iloc[:300]\n",
    "# train_index = list(range(0, 241))\n",
    "# test_index = list(range(241, 301))\n",
    "\n",
    "df = pd.read_csv(\"English_fiction_pre_PCA_3.csv\")\n",
    "train_df = pd.read_csv(\"original_data/train_indices.csv\")\n",
    "test_df = pd.read_csv(\"original_data/test_indices.csv\")\n",
    "train_index = train_df[\"index\"].tolist()\n",
    "test_index = test_df[\"index\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d942066-7911-4454-8e6f-c8e82bc5756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_nouns(text):\n",
    "    \"\"\"\n",
    "    concatenate and apply lowercase lettering to proper nouns like names, publishers, and book titles\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: remove leading or ending brackets (if applicable) and internal quote marks\n",
    "    text = text.strip(\"[]\")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "\n",
    "    # Step 2: If there are multiple nouns, split at the comma\n",
    "    text = text.split(\", \")\n",
    "\n",
    "    # Step 3: Concatenate each noun and put all letters in lowercase:\n",
    "    text = [x.replace(\" \", \"\").lower() for x in text]\n",
    "\n",
    "    # Step 4: Convert the list of tokens to a string\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def add_tokens_to_description(df):\n",
    "    df[\"description\"] += \" \" + df[\"authors\"].apply(concat_nouns)\n",
    "    df[\"description\"] += \" \" + df[\"publisher\"].apply(concat_nouns)\n",
    "    df[\"description\"] += \" \" + df[\"Title\"].str.lower()\n",
    "\n",
    "def calculate_ngrams_RAKE(text: str):\n",
    "    r_unigram = Rake()\n",
    "    r_unigram.extract_keywords_from_text(text)\n",
    "    \n",
    "    keyword_dict_scores = r_unigram.get_word_degrees()\n",
    "    words = list(keyword_dict_scores.keys())\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "def create_tokens(df, input_column: str, output_column: str):  \n",
    "    df[output_column] = df[\"description\"].apply(calculate_ngrams_RAKE)\n",
    "\n",
    "# Calculate tfidf matrix:\n",
    "def calculate_TFIDF(df, BOW_column: str, train_index, test_index):\n",
    "    # Split the incoming dataframe into train and test slices base on the list of train and test indices provided:\n",
    "    X_train_df = df[df[\"index\"].isin(train_index)]\n",
    "    X_test_df = df[df[\"index\"].isin(test_index)]\n",
    "    \n",
    "    #instantiating and generating the tfidf\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train_df[BOW_column])\n",
    "    X_test_tfidf = vectorizer.transform(X_test_df[BOW_column])\n",
    "\n",
    "    # convert the tfidf matrix to a dense matrix\n",
    "    dense_X_train_tfidf = X_train_tfidf.toarray()\n",
    "    dense_X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "    # # combine the arrays:\n",
    "    # dense_X = np.concatenate((dense_X_train_tfidf, dense_X_test_tfidf), axis = 0)\n",
    "\n",
    "    # Determine the column names for our dense matrix and create a dataframe with the \n",
    "    # vocabulary as columns:\n",
    "    temp_dict = {}\n",
    "    for counter, i in enumerate(list(vectorizer.vocabulary_.items())):\n",
    "            temp_dict[i[1]] = i[0]\n",
    "    \n",
    "    column_names = []\n",
    "    for i in range(len(temp_dict)):\n",
    "        column_names.append(temp_dict[i])\n",
    "\n",
    "    # Convert the array back into a dataframe:\n",
    "    scaled_dataframe_X_train=pd.DataFrame(dense_X_train_tfidf, columns= column_names)\n",
    "    scaled_dataframe_X_test=pd.DataFrame(dense_X_test_tfidf, columns= column_names) \n",
    "\n",
    "    return scaled_dataframe_X_train, scaled_dataframe_X_test, column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc517f4d-917b-493a-a260-2ff9f97c5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tokens from other columns to the description column, specifically author, title, and publisher\n",
    "add_tokens_to_description(df)\n",
    "\n",
    "# Create tokens from the book descriptions and save this in a new column called \"tokens\"\n",
    "create_tokens(df, \"description\", \"tokens\")\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, column_names = calculate_TFIDF(df, \"tokens\", train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c1b51953-e38e-44e8-a8a5-3e1a38b28299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21419, 80652)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "296fe87d-edaa-48e9-9d43-0c713b0159b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01 0.   0.   ... 0.   0.   0.  ]\n",
      " [0.02 0.   0.02 ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.03]\n",
      " ...\n",
      " [0.   0.   0.   ... 0.01 0.   0.03]\n",
      " [0.   0.   0.   ... 0.   0.01 0.03]\n",
      " [0.01 0.   0.   ... 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "NMF_model = NMF(n_components=20)\n",
    "\n",
    "# Fit the model to the training tfidf matrix\n",
    "NMF_model.fit(X_train_tfidf)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = NMF_model.transform(X_train_tfidf)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "21cd009c-3070-45fd-acdf-4e8a1e09e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_features_test = NMF_model.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8084df97-a954-4404-88a3-5aa10acf4c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21419\n",
      "5355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5355, 20)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_index))\n",
    "nmf_features.shape\n",
    "\n",
    "print(len(test_index))\n",
    "nmf_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bd253b7-7383-4b23-afb4-ebc8cffa2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df = pd.DataFrame(NMF_model.components_, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1878f9cf-bc46-4b3a-b7ef-11824c73e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 80652)\n",
      "world        0.492523\n",
      "must         0.470366\n",
      "war          0.387650\n",
      "earth        0.340529\n",
      "evil         0.310199\n",
      "battle       0.295096\n",
      "planet       0.274775\n",
      "power        0.269674\n",
      "adventure    0.256672\n",
      "land         0.251698\n",
      "dark         0.245385\n",
      "ancient      0.243311\n",
      "series       0.240151\n",
      "find         0.238756\n",
      "save         0.237210\n",
      "forces       0.231866\n",
      "magic        0.221743\n",
      "mission      0.220035\n",
      "enemy        0.219619\n",
      "future       0.218489\n",
      "Name: 16, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Select row 3: component\n",
    "component = components_df.iloc[16]\n",
    "\n",
    "# Print result of nlargest\n",
    "print(component.nlargest(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ddd560bf-5d8f-4fd9-8035-b25f0bb2de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {0: \"nostalgia\", \n",
    "          1: \"self-published/debut\",\n",
    "          2: \"story/anthology\",\n",
    "          3: \"womens_fiction\",\n",
    "          4: \"childrens_books\",\n",
    "          5: \"classic\",\n",
    "          6: \"family_drama\",\n",
    "          7: \"digital_books/recreations\",\n",
    "          8: \"reproduced\",\n",
    "          9: \"murder_mystery\",\n",
    "          10: \"reprint\",\n",
    "          11: \"bestselling_author\",\n",
    "          12: \"romance\",\n",
    "          13: \"unkonwn\",\n",
    "          14: \"teen\",\n",
    "          15: \"novel\",\n",
    "          16: \"world/war/historical_fiction\",\n",
    "          17: \"unknown\",\n",
    "          18: \"young_adult\",\n",
    "          19: \"coming_of_age\",\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ac667d93-cafe-4444-95ca-295e8c3f167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02]\n",
      "['romance']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Always The Chaperon And Never The Bride... At least, that's the way it was for Lady Annis Wyncherley. If this young widow was to remain as chaperon to society's misses, there could be no hint of scandal attached to her name. Rakes and romance were strictly off-limits, most especially a rogue like the handsome Lord Adam Ashwick! But that proved nearly impossible when Adam made his daughter's chaperon the subject of his relentless seduction. Adam knew any attention from him could destroy Lady Wyncherley's fine reputation. But he was powerless to control the strong desires she aroused in him. And all too soon this reformed rogue was hell-bent on convincing a very stubborn Annis to become his chaperon bride.... nicolacornick harlequin chaperon bride, the (historical romance)\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df = df[df[\"index\"].isin(train_index)]\n",
    "X_test_df = df[df[\"index\"].isin(test_index)]\n",
    "book_index = 12\n",
    "\n",
    "# retrieve the nmf features for a predefined index\n",
    "nmf_feature_list = nmf_features_test[book_index].round(2).tolist()\n",
    "print(nmf_feature_list)\n",
    "\n",
    "# calculate the maxium nmf value(s)\n",
    "max_nmf_value = max(nmf_feature_list)\n",
    "\n",
    "# find the indices in the nmf feature list to be used to convert the values to category labels\n",
    "indices = [i for i, x in enumerate(nmf_feature_list) if x == max_nmf_value]\n",
    "indices\n",
    "\n",
    "category_label = [topics[i] for i in indices]\n",
    "print(category_label)\n",
    "X_test_df[\"description\"].iloc[book_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0236e678-c010-461f-9ac2-116136a210cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nmf_features.shape[1]):\n",
    "    location= X_train_df.shape[1]\n",
    "    X_train_df.insert(location, topics[i], nmf_features[:,i].tolist())\n",
    "\n",
    "for i in range(nmf_features_test.shape[1]):\n",
    "    location= X_test_df.shape[1]\n",
    "    X_test_df.insert(location, topics[i], nmf_features_test[:,i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e5633940-ecf6-4619-be56-918ff352c5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5355, 20)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "697d4701-55f9-4bc0-8669-9e6ed82d15f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "43fc63a2-b2bf-4094-ae18-5f198faa9f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21419, 39)\n",
      "(5355, 39)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_df.shape)\n",
    "print(X_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6835e915-ae42-40bd-a1a8-94354fa72b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nostalgia'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2447851b-a151-477e-8079-a0060cd94943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>publisher</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>categories</th>\n",
       "      <th>index</th>\n",
       "      <th>reviews number</th>\n",
       "      <th>...</th>\n",
       "      <th>reprint</th>\n",
       "      <th>bestselling_author</th>\n",
       "      <th>romance</th>\n",
       "      <th>unkonwn</th>\n",
       "      <th>teen</th>\n",
       "      <th>novel</th>\n",
       "      <th>world/war/historical_fiction</th>\n",
       "      <th>unknown</th>\n",
       "      <th>young_adult</th>\n",
       "      <th>coming_of_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>['fiction']</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Forbidden Stories of Marta Veneranda</td>\n",
       "      <td>Marta Veneranda, a Latina neoyorkina, finds th...</td>\n",
       "      <td>['Sonia Rivera-Valdes']</td>\n",
       "      <td>http://books.google.com/books/content?id=A7aYb...</td>\n",
       "      <td>http://books.google.nl/books?id=A7aYbAvagu8C&amp;p...</td>\n",
       "      <td>Seven Stories Press</td>\n",
       "      <td>http://books.google.nl/books?id=A7aYbAvagu8C&amp;d...</td>\n",
       "      <td>['fiction']</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "0             Whispers of the Wicked Saints   \n",
       "1  The Forbidden Stories of Marta Veneranda   \n",
       "\n",
       "                                         description                  authors  \\\n",
       "0  Julia Thomas finds her life spinning out of co...      ['Veronica Haddon']   \n",
       "1  Marta Veneranda, a Latina neoyorkina, finds th...  ['Sonia Rivera-Valdes']   \n",
       "\n",
       "                                               image  \\\n",
       "0  http://books.google.com/books/content?id=aRSIg...   \n",
       "1  http://books.google.com/books/content?id=A7aYb...   \n",
       "\n",
       "                                         previewLink            publisher  \\\n",
       "0  http://books.google.nl/books?id=aRSIgJlq6JwC&d...            iUniverse   \n",
       "1  http://books.google.nl/books?id=A7aYbAvagu8C&p...  Seven Stories Press   \n",
       "\n",
       "                                            infoLink   categories  index  \\\n",
       "0  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  ['fiction']      3   \n",
       "1  http://books.google.nl/books?id=A7aYbAvagu8C&d...  ['fiction']     24   \n",
       "\n",
       "   reviews number  ...   reprint  bestselling_author   romance unkonwn  \\\n",
       "0              32  ...  0.001315                 0.0  0.040636     0.0   \n",
       "1               1  ...  0.000000                 0.0  0.009457     0.0   \n",
       "\n",
       "       teen     novel  world/war/historical_fiction unknown young_adult  \\\n",
       "0  0.000214  0.000000                      0.010339     0.0         0.0   \n",
       "1  0.000000  0.006398                      0.000197     0.0         0.0   \n",
       "\n",
       "   coming_of_age  \n",
       "0       0.000000  \n",
       "1       0.000621  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a1961323-6851-40bb-a56d-686c73362e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.to_csv(\n",
    "path_or_buf = \"X_train_NMF_topics.csv\",\n",
    "index = False\n",
    ")\n",
    "\n",
    "X_test_df.to_csv(\n",
    "path_or_buf = \"X_test_NMF_topics.csv\",\n",
    "index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae03eac-659e-4d96-93dc-bda70d606546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
